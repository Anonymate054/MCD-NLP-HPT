{"cells":[{"cell_type":"markdown","metadata":{"cell_id":"ec67bcd310ce482f9a46f9d55432c449","deepnote_cell_type":"markdown"},"source":"# Preparing the data","block_group":"13ce7c050cc54d909015908019c84eed"},{"cell_type":"code","metadata":{"source_hash":"f61b930d","execution_start":1733896398226,"execution_millis":1,"execution_context_id":"41cfbd2e-b280-45a1-b4a8-14620261accf","cell_id":"90a53e47ccfc402bb63627e984c06a89","deepnote_cell_type":"code"},"source":"from sklearn.metrics import accuracy_score, precision_score, recall_score\nfrom nltk.probability import FreqDist\nimport pandas as pd\nimport ast\nimport fs","block_group":"63e0f8ce2da542ea84ae861ee5b5c5c1","execution_count":3,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":"647472ee","execution_start":1733897383298,"execution_millis":0,"execution_context_id":"41cfbd2e-b280-45a1-b4a8-14620261accf","cell_id":"a96b61bd2d304472bce3bba098123c86","deepnote_cell_type":"code"},"source":"PROCESSED_FILES_DIR = fs.open_fs(\"MCD-NLP-HPT/data/processed\")\nTRAIN_DIR = PROCESSED_FILES_DIR.getsyspath(\"train.csv\")\nTEST_DIR = PROCESSED_FILES_DIR.getsyspath(\"test.csv\")\nVAL_DIR = PROCESSED_FILES_DIR.getsyspath(\"validation.csv\")\n\nINTERIM_COMMENTS_CLEANED_ONLY_SW_DIR = INTERIM_FILES_DIR.getsyspath(\"Comments_cleaned_only_sw.csv\")\nTRAIN_ONLY_SW_DIR = PROCESSED_FILES_DIR.getsyspath(\"train_only_sw.csv\")\nTEST_ONLY_SW_DIR = PROCESSED_FILES_DIR.getsyspath(\"test_only_sw.csv\")\nVAL_ONLY_SW_DIR = PROCESSED_FILES_DIR.getsyspath(\"validation_only_sw.csv\")","block_group":"8cbe80a94fb5478d9726dabd8b8b134f","execution_count":17,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","metadata":{"cell_id":"e25864d785f24e4094721c45a8e94685","deepnote_cell_type":"markdown"},"source":"### Clase principal para el algoritmo\n\nRecuerda que la clase más probable viene dada por (en espacio de cómputo logarítmico): \n\n\n$$\\hat{c} = {\\arg \\max}_{(c)}\\log{P(c)}\n +\\sum_{i=1}^n\n\\log{ P(f_i \\vert c)}\n$$\n\nDonde, para evitar casos atípicos, usaremos el suavizado de Laplace así:\n\n$$\nP(f_i \\vert c) = \\frac{C(f_i, c)+1}{C(c) + \\vert V \\vert}\n$$\n\nsiendo $\\vert V \\vert$ la longitud del vocabulario de nuestro conjunto de entrenamiento. ","block_group":"731aea3f5cde46498fd9615ca4692c75"},{"cell_type":"code","metadata":{"source_hash":"35166b4","execution_start":1733897413162,"execution_millis":0,"execution_context_id":"41cfbd2e-b280-45a1-b4a8-14620261accf","cell_id":"50b059ebeab54b418a67a364f03bb89e","deepnote_cell_type":"code"},"source":"import math\nfrom collections import defaultdict\nfrom nltk.probability import FreqDist\nimport numpy as np\n\n\nclass NaiveBayesClassifier:\n    def __init__(self):\n        self.unique_classes = set()\n        self.vocab = set()\n        self.class_count = {}  # C(c)\n        self.log_class_prior_prob = {}  # P(c)\n        self.word_conditional_counts = defaultdict(lambda: defaultdict(float))  # C(w|c)\n\n    def fit(self, x_data, y_data):\n        \"\"\"\n        Train the Naive Bayes Classifier on the given data.\n        :param x_data: List of tokenized texts.\n        :param y_data: List of class labels corresponding to x_data.\n        \"\"\"\n        num_samples = len(x_data)\n        self.unique_classes = set(y_data)\n\n        # Count occurrences of each class\n        for cls in y_data:\n            self.class_count[cls] = self.class_count.get(cls, 0) + 1\n\n        # Compute log prior probabilities for each class\n        for cls, count in self.class_count.items():\n            self.log_class_prior_prob[cls] = math.log(count / num_samples)\n\n        # Count word occurrences per class\n        for tokens, cls in zip(x_data, y_data):\n            counts = FreqDist(tokens)\n            for word, count in counts.items():\n                self.vocab.add(word)\n                self.word_conditional_counts[cls][word] += count\n\n    def predict(self, data):\n        \"\"\"\n        Predict class labels for the given data.\n        :param data: List of tokenized texts.\n        :return: List of predicted class labels.\n        \"\"\"\n        results = []\n\n        for text in data:\n            words = set(FreqDist(text))  # Unique words in the text\n            score_prob = {}\n\n            for cls in self.unique_classes:\n                # Initialize with prior probability\n                score_prob[cls] = self.log_class_prior_prob[cls]\n\n                for word in words:\n                    if word in self.vocab:\n                        # Laplace smoothing\n                        word_count = self.word_conditional_counts[cls].get(word, 0.0)\n                        log_word_prob = math.log(\n                            (word_count + 1) / (self.class_count[cls] + len(self.vocab))\n                        )\n                        score_prob[cls] += log_word_prob\n\n            # Find the class with the highest score\n            predicted_class = max(score_prob, key=score_prob.get)\n            results.append(predicted_class)\n\n        return results","block_group":"c0e358e7a003495f9bcbc1d9d8719499","execution_count":18,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":"bd0c498b","execution_start":1733896416894,"execution_millis":1189,"execution_context_id":"41cfbd2e-b280-45a1-b4a8-14620261accf","cell_id":"905920328f154263a9231915f260a1c7","deepnote_cell_type":"code"},"source":"df_train = pd.read_csv(TRAIN_DIR)\ndf_test = pd.read_csv(TEST_DIR)\ndf_val = pd.read_csv(VAL_DIR)","block_group":"62bbf98a61c64af79affa79cd94fa606","execution_count":7,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":"b122535b","execution_start":1733897431314,"execution_millis":620,"execution_context_id":"41cfbd2e-b280-45a1-b4a8-14620261accf","cell_id":"24b3415ce2a94bfdb0764ae9ce9d61cf","deepnote_cell_type":"code"},"source":"df_train_2 = pd.read_csv(TRAIN_ONLY_SW_DIR)\ndf_test_2 = pd.read_csv(TEST_ONLY_SW_DIR)\ndf_val_2 = pd.read_csv(VAL_ONLY_SW_DIR)","block_group":"cf4a69cb643d433a85e408fff4fdac07","execution_count":19,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":"591d3b8d","execution_start":1733896418246,"execution_millis":7,"deepnote_table_state":{"sortBy":[],"filters":[],"pageSize":10,"pageIndex":0,"hiddenColumnIds":[],"conditionalFilters":[],"cellFormattingRules":[],"wrappedTextColumnIds":[]},"execution_context_id":"41cfbd2e-b280-45a1-b4a8-14620261accf","deepnote_table_loading":false,"cell_id":"b5b35a61c2814a52894342e097b8ded1","deepnote_cell_type":"code"},"source":"df_train","block_group":"705d936ea4574e0cade471ecf4f9f2fd","execution_count":8,"outputs":[{"output_type":"execute_result","execution_count":8,"data":{"application/vnd.deepnote.dataframe.v3+json":{"column_count":14,"row_count":922,"columns":[{"name":"id","dtype":"object","stats":{"unique_count":922,"nan_count":0,"categories":[{"name":"UgwtT3n4ZD6aX2c3NrF4AaABAg","count":1},{"name":"Ugzlbev9x6glV6YNpyN4AaABAg","count":1},{"name":"920 others","count":920}]}},{"name":"videoId","dtype":"object","stats":{"unique_count":25,"nan_count":0,"categories":[{"name":"RBnZPFhDcnk","count":76},{"name":"ShW6FY-vbmo","count":53},{"name":"23 others","count":793}]}},{"name":"textOriginal","dtype":"object","stats":{"unique_count":908,"nan_count":0,"categories":[{"name":"Imperio japonés pt4 plis","count":12},{"name":"Este capítulo debió llamarse las flipantes aventuras del reinado de hispania. Olé!","count":2},{"name":"906 others","count":908}]}},{"name":"authorDisplayName","dtype":"object","stats":{"unique_count":634,"nan_count":8,"categories":[{"name":"@ivanmelchor2889","count":14},{"name":"633 others","count":900},{"name":"Missing","count":8}]}},{"name":"likeCount","dtype":"int64","stats":{"unique_count":23,"nan_count":0,"min":"0","max":"43","histogram":[{"bin_start":0,"bin_end":4.3,"count":870},{"bin_start":4.3,"bin_end":8.6,"count":27},{"bin_start":8.6,"bin_end":12.899999999999999,"count":11},{"bin_start":12.899999999999999,"bin_end":17.2,"count":4},{"bin_start":17.2,"bin_end":21.5,"count":3},{"bin_start":21.5,"bin_end":25.799999999999997,"count":4},{"bin_start":25.799999999999997,"bin_end":30.099999999999998,"count":1},{"bin_start":30.099999999999998,"bin_end":34.4,"count":1},{"bin_start":34.4,"bin_end":38.699999999999996,"count":0},{"bin_start":38.699999999999996,"bin_end":43,"count":1}]}},{"name":"publishedAt","dtype":"object","stats":{"unique_count":922,"nan_count":0,"categories":[{"name":"2024-04-18T13:32:34Z","count":1},{"name":"2024-06-26T05:30:57Z","count":1},{"name":"920 others","count":920}]}},{"name":"category_id","dtype":"int64","stats":{"unique_count":7,"nan_count":0,"min":"1","max":"7","histogram":[{"bin_start":1,"bin_end":1.6,"count":82},{"bin_start":1.6,"bin_end":2.2,"count":151},{"bin_start":2.2,"bin_end":2.8,"count":0},{"bin_start":2.8,"bin_end":3.4,"count":62},{"bin_start":3.4,"bin_end":4,"count":0},{"bin_start":4,"bin_end":4.6,"count":115},{"bin_start":4.6,"bin_end":5.2,"count":194},{"bin_start":5.2,"bin_end":5.8,"count":0},{"bin_start":5.8,"bin_end":6.3999999999999995,"count":206},{"bin_start":6.3999999999999995,"bin_end":7,"count":112}]}},{"name":"category_description","dtype":"object","stats":{"unique_count":7,"nan_count":0,"categories":[{"name":"Comentarios humorísticos o memes","count":206},{"name":"Felicitaciones y agradecimientos","count":194},{"name":"5 others","count":522}]}},{"name":"Tokens_full","dtype":"object","stats":{"unique_count":904,"nan_count":0,"categories":[{"name":"['Imperio', 'japonés', 'pt4', 'plis']","count":12},{"name":"[]","count":6},{"name":"902 others","count":904}]}},{"name":"Tokens","dtype":"object","stats":{"unique_count":904,"nan_count":0,"categories":[{"name":"['Imperio', 'japonés', 'pt4', 'plis']","count":12},{"name":"[]","count":6},{"name":"902 others","count":904}]}},{"name":"Tokens_without_stopwords","dtype":"object","stats":{"unique_count":903,"nan_count":0,"categories":[{"name":"['Imperio', 'japonés', 'pt4', 'plis']","count":12},{"name":"[]","count":6},{"name":"901 others","count":904}]}},{"name":"Tokens_without_stopwords_stemmed","dtype":"object","stats":{"unique_count":902,"nan_count":0,"categories":[{"name":"['imperi', 'japones', 'pt4', 'plis']","count":12},{"name":"[]","count":6},{"name":"900 others","count":904}]}},{"name":"Tokens_lemmatized","dtype":"object","stats":{"unique_count":908,"nan_count":0,"categories":[{"name":"['imperio', 'japonés', 'pt4', 'plis']","count":12},{"name":"['este', 'capítulo', 'deber', 'llamar', 'él', 'el', 'flipante', 'aventura', 'de', 'el', 'reinado', 'de', 'hispania', '.', 'olé', '!']","count":2},{"name":"906 others","count":908}]}},{"name":"Tokens_without_stopwords_lemmatized","dtype":"object","stats":{"unique_count":903,"nan_count":0,"categories":[{"name":"['imperio', 'japonés', 'pt4', 'plis']","count":12},{"name":"[]","count":6},{"name":"901 others","count":904}]}},{"name":"_deepnote_index_column","dtype":"int64"}],"rows":[{"id":"UgwtT3n4ZD6aX2c3NrF4AaABAg","videoId":"FXxcNjTZ4qo","textOriginal":"No es un mito, Paraguay 🇵🇾 si existe.....","authorDisplayName":"@rosaelenarolonespinosa4666","likeCount":1,"publishedAt":"2024-04-18T13:32:34Z","category_id":7,"category_description":"Comentarios generales","Tokens_full":"['No', 'es', 'un', 'mito', ',', 'Paraguay', 'si', 'existe', '...', '.', '.']","Tokens":"['No', 'es', 'un', 'mito', 'Paraguay', 'si', 'existe', '...']","Tokens_without_stopwords":"['No', 'mito', 'Paraguay', 'si', 'existe', '...']","Tokens_without_stopwords_stemmed":"['no', 'mit', 'paraguay', 'si', 'exist', '...']","Tokens_lemmatized":"['no', 'ser', 'uno', 'mito', ',', 'paraguay', '🇵🇾', 'si', 'existir', '.....']","Tokens_without_stopwords_lemmatized":"['no', 'mito', 'paraguay', 'si', 'existir', '...']","_deepnote_index_column":0},{"id":"Ugzlbev9x6glV6YNpyN4AaABAg","videoId":"CPCN1Lqzc2U","textOriginal":"Un podcast sobre la radio con DIANA URIBE, la mejor radio historiadora de Latinoamérica ❤","authorDisplayName":"@KarimVG","likeCount":0,"publishedAt":"2024-06-26T05:30:57Z","category_id":5,"category_description":"Felicitaciones y agradecimientos","Tokens_full":"['Un', 'podcast', 'sobre', 'la', 'radio', 'con', 'DIANA', 'URIBE', ',', 'la', 'mejor', 'radio', 'historiadora', 'de', 'Latinoamérica']","Tokens":"['Un', 'podcast', 'sobre', 'la', 'radio', 'con', 'DIANA', 'URIBE', 'la', 'mejor', 'radio', 'historiadora', 'de', 'Latinoamérica']","Tokens_without_stopwords":"['Un', 'podcast', 'radio', 'DIANA', 'URIBE', 'mejor', 'radio', 'historiadora', 'Latinoamérica']","Tokens_without_stopwords_stemmed":"['un', 'podcast', 'radi', 'dian', 'urib', 'mejor', 'radi', 'histori', 'latinoamer']","Tokens_lemmatized":"['uno', 'podcast', 'sobre', 'el', 'radio', 'con', 'diana', 'URIBE', ',', 'el', 'mejor', 'radio', 'historiador', 'de', 'latinoamérica', '❤']","Tokens_without_stopwords_lemmatized":"['uno', 'podcast', 'radio', 'diana', 'URIBE', 'mejor', 'radio', 'historiadora', 'latinoamérica']","_deepnote_index_column":1},{"id":"UgzIKrDRdcGk13aMtul4AaABAg","videoId":"ShW6FY-vbmo","textOriginal":"Cada vez que los escucho, muero de risa y me dan ganas de abrir una cervecita. Saludos desde República Dominicana.","authorDisplayName":"@ceciliamendiola8646","likeCount":2,"publishedAt":"2024-06-18T21:15:49Z","category_id":6,"category_description":"Comentarios humorísticos o memes","Tokens_full":"['Cada', 'vez', 'que', 'los', 'escucho', ',', 'muero', 'de', 'risa', 'y', 'me', 'dan', 'ganas', 'de', 'abrir', 'una', 'cervecita', '.', 'Saludos', 'desde', 'República', 'Dominicana', '.']","Tokens":"['Cada', 'vez', 'que', 'los', 'escucho', 'muero', 'de', 'risa', 'y', 'me', 'dan', 'ganas', 'de', 'abrir', 'una', 'cervecita', 'Saludos', 'desde', 'República', 'Dominicana']","Tokens_without_stopwords":"['Cada', 'vez', 'escucho', 'muero', 'risa', 'dan', 'ganas', 'abrir', 'cervecita', 'Saludos', 'República', 'Dominicana']","Tokens_without_stopwords_stemmed":"['cad', 'vez', 'escuch', 'muer', 'ris', 'dan', 'gan', 'abrir', 'cervecit', 'salud', 'republ', 'dominican']","Tokens_lemmatized":"['cada', 'vez', 'que', 'él', 'escuchar', ',', 'muero', 'de', 'risa', 'y', 'yo', 'dar', 'gana', 'de', 'abrir', 'uno', 'cervecito', '.', 'saludo', 'desde', 'república', 'Dominicana', '.']","Tokens_without_stopwords_lemmatized":"['cada', 'vez', 'escuchar', 'muero', 'risa', 'dar', 'gana', 'abrir', 'cervecito', 'saludo', 'república', 'Dominicana']","_deepnote_index_column":2},{"id":"Ugz5Q5R5ls4pXTXSi294AaABAg","videoId":"HxMXLWqe9HQ","textOriginal":"Que buen capitulo, son geniales! El cristo del corcovado en mood esa no es tu familia jajaja 😂 como había que hacer para pedirles su intinerario de Japón?","authorDisplayName":"@anaberthalyochoaporras8262","likeCount":0,"publishedAt":"2024-09-19T04:47:09Z","category_id":5,"category_description":"Felicitaciones y agradecimientos","Tokens_full":"['Que', 'buen', 'capitulo', ',', 'son', 'geniales', 'El', 'cristo', 'del', 'corcovado', 'en', 'mood', 'esa', 'no', 'es', 'tu', 'familia', 'jajaja', 'como', 'había', 'que', 'hacer', 'para', 'pedirles', 'su', 'intinerario', 'de', 'Japón', '?']","Tokens":"['Que', 'buen', 'capitulo', 'son', 'geniales', 'El', 'cristo', 'del', 'corcovado', 'en', 'mood', 'esa', 'no', 'es', 'tu', 'familia', 'jajaja', 'como', 'había', 'que', 'hacer', 'para', 'pedirles', 'su', 'intinerario', 'de', 'Japón']","Tokens_without_stopwords":"['Que', 'buen', 'capitulo', 'geniales', 'El', 'cristo', 'corcovado', 'mood', 'familia', 'jajaja', 'hacer', 'pedirles', 'intinerario', 'Japón']","Tokens_without_stopwords_stemmed":"['que', 'buen', 'capitul', 'genial', 'el', 'crist', 'corcov', 'mood', 'famili', 'jajaj', 'hac', 'ped', 'intinerari', 'japon']","Tokens_lemmatized":"['que', 'buen', 'capitulo', ',', 'ser', 'genial', '!', 'el', 'cristo', 'de', 'el', 'corcovado', 'en', 'mood', 'ese', 'no', 'ser', 'tu', 'familia', 'jajajar', '😂', 'como', 'haber', 'que', 'hacer', 'para', 'pedir', 'él', 'su', 'intinerario', 'de', 'Japón', '?']","Tokens_without_stopwords_lemmatized":"['que', 'buen', 'capitulo', 'genial', 'el', 'cristo', 'corcovado', 'mood', 'familia', 'jajajar', 'hacer', 'pedir', 'intinerario', 'Japón']","_deepnote_index_column":3},{"id":"UgwKlLDQnWVL_LOpE1d4AaABAg","videoId":"wCm4FNSnDPs","textOriginal":"Gracias por el podcast de la semana, mis amores. Los extrañé ❤","authorDisplayName":"@LadySkywalkerW","likeCount":0,"publishedAt":"2024-10-11T03:38:25Z","category_id":5,"category_description":"Felicitaciones y agradecimientos","Tokens_full":"['Gracias', 'por', 'el', 'podcast', 'de', 'la', 'semana', ',', 'mis', 'amores', '.', 'Los', 'extrañé']","Tokens":"['Gracias', 'por', 'el', 'podcast', 'de', 'la', 'semana', 'mis', 'amores', 'Los', 'extrañé']","Tokens_without_stopwords":"['Gracias', 'podcast', 'semana', 'amores', 'Los', 'extrañé']","Tokens_without_stopwords_stemmed":"['graci', 'podcast', 'seman', 'amor', 'los', 'extrañ']","Tokens_lemmatized":"['gracia', 'por', 'el', 'podcast', 'de', 'el', 'semana', ',', 'mi', 'amor', '.', 'él', 'extrañar', '❤']","Tokens_without_stopwords_lemmatized":"['gracia', 'podcast', 'semana', 'amor', 'el', 'extrañar']","_deepnote_index_column":4},{"id":"UgxFgSY23PWWMQfjUqt4AaABAg","videoId":"CPCN1Lqzc2U","textOriginal":"Los paraguayos llevamos toda la vida tenido una relación como de perros y gatos con los argentinos cuando en realidad deberíamos tener esa relación con los Brasileños jajaj, es broma 😉 \nSon cosas que tenemos que dejar donde están, que es el PASADO y que ojalá no se vuelva a repetir nunca xq si vuelve a pasar eso ahora, Paraguay si que desaparecería, la economía que tuvimos antes del guerra de la triple alianza jamás volvió 🥲\nUn saludo 🫶🏻siempre los escucho en el trabajo.","authorDisplayName":"@lauraflores7242","likeCount":2,"publishedAt":"2024-06-27T14:03:52Z","category_id":3,"category_description":"Experiencias personales","Tokens_full":"['Los', 'paraguayos', 'llevamos', 'toda', 'la', 'vida', 'tenido', 'una', 'relación', 'como', 'de', 'perros', 'y', 'gatos', 'con', 'los', 'argentinos', 'cuando', 'en', 'realidad', 'deberíamos', 'tener', 'esa', 'relación', 'con', 'los', 'Brasileños', 'jajaj', ',', 'es', 'broma', 'Son', 'cosas', 'que', 'tenemos', 'que', 'dejar', 'donde', 'están', ',', 'que', 'es', 'el', 'PASADO', 'y', 'que', 'ojalá', 'no', 'se', 'vuelva', 'a', 'repetir', 'nunca', 'xq', 'si', 'vuelve', 'a', 'pasar', 'eso', 'ahora', ',', 'Paraguay', 'si', 'que', 'desaparecería', ',', 'la', 'economía', 'que', 'tuvimos', 'antes', 'del', 'guerra', 'de', 'la', 'triple', 'alianza', 'jamás', 'volvió', 'Un', 'saludo', 'siempre', 'los', 'escucho', 'en', 'el', 'trabajo', '.']","Tokens":"['Los', 'paraguayos', 'llevamos', 'toda', 'la', 'vida', 'tenido', 'una', 'relación', 'como', 'de', 'perros', 'y', 'gatos', 'con', 'los', 'argentinos', 'cuando', 'en', 'realidad', 'deberíamos', 'tener', 'esa', 'relación', 'con', 'los', 'Brasileños', 'jajaj', 'es', 'broma', 'Son', 'cosas', 'que', 'tenemos', 'que', 'dejar', 'donde', 'están', 'que', 'es', 'el', 'PASADO', 'y', 'que', 'ojalá', 'no', 'se', 'vuelva', 'a', 'repetir', 'nunca', 'xq', 'si', 'vuelve', 'a', 'pasar', 'eso', 'ahora', 'Paraguay', 'si', 'que', 'desaparecería', 'la', 'economía', 'que', 'tuvimos', 'antes', 'del', 'guerra', 'de', 'la', 'triple', 'alianza', 'jamás', 'volvió', 'Un', 'saludo', 'siempre', 'los', 'escucho', 'en', 'el', 'trabajo']","Tokens_without_stopwords":"['Los', 'paraguayos', 'llevamos', 'toda', 'vida', 'relación', 'perros', 'gatos', 'argentinos', 'realidad', 'deberíamos', 'tener', 'relación', 'Brasileños', 'jajaj', 'broma', 'Son', 'cosas', 'dejar', 'PASADO', 'ojalá', 'vuelva', 'repetir', 'nunca', 'xq', 'si', 'vuelve', 'pasar', 'ahora', 'Paraguay', 'si', 'desaparecería', 'economía', 'guerra', 'triple', 'alianza', 'jamás', 'volvió', 'Un', 'saludo', 'siempre', 'escucho', 'trabajo']","Tokens_without_stopwords_stemmed":"['los', 'paraguay', 'llev', 'tod', 'vid', 'relacion', 'perr', 'gat', 'argentin', 'realid', 'deb', 'ten', 'relacion', 'brasileñ', 'jajaj', 'brom', 'son', 'cos', 'dej', 'pas', 'ojal', 'vuelv', 'repet', 'nunc', 'xq', 'si', 'vuelv', 'pas', 'ahor', 'paraguay', 'si', 'desaparec', 'econom', 'guerr', 'tripl', 'alianz', 'jamas', 'volv', 'un', 'salud', 'siempr', 'escuch', 'trabaj']","Tokens_lemmatized":"['el', 'paraguayo', 'llevar', 'todo', 'el', 'vida', 'tener', 'uno', 'relación', 'como', 'de', 'perro', 'y', 'gato', 'con', 'el', 'argentino', 'cuando', 'en', 'realidad', 'deber', 'tener', 'ese', 'relación', 'con', 'el', 'Brasileños', 'jajaj', ',', 'ser', 'broma', '😉', 'ser', 'cosa', 'que', 'tener', 'que', 'dejar', 'donde', 'estar', ',', 'que', 'ser', 'el', 'PASADO', 'y', 'que', 'ojalá', 'no', 'él', 'volver', 'a', 'repetir', 'nunca', 'xq', 'si', 'volver', 'a', 'pasar', 'ese', 'ahora', ',', 'paraguay', 'si', 'que', 'desaparecer', ',', 'el', 'economía', 'que', 'tener', 'antes', 'de', 'el', 'guerra', 'de', 'el', 'triple', 'alianza', 'jamás', 'volver', '🥲', 'uno', 'saludo', '🫶🏻siempre', 'él', 'escuchar', 'en', 'el', 'trabajo', '.']","Tokens_without_stopwords_lemmatized":"['el', 'paraguayo', 'llevar', 'todo', 'vida', 'relación', 'perro', 'gato', 'argentino', 'realidad', 'deber', 'tener', 'relación', 'Brasileños', 'jajaj', 'broma', 'ser', 'cosa', 'dejar', 'pasado', 'ojalá', 'volver', 'repetir', 'nunca', 'xq', 'si', 'volver', 'pasar', 'ahora', 'paraguay', 'si', 'desaparecer', 'economía', 'guerra', 'triple', 'alianza', 'jamás', 'volver', 'uno', 'saludo', 'siempre', 'escuchar', 'trabajo']","_deepnote_index_column":5},{"id":"Ugwz1snOc8tFwlY2MbF4AaABAg","videoId":"RBnZPFhDcnk","textOriginal":"Que pedo con la gente que se queja de que digan groserías, cuando es parte de la chispa que tiene el podcast. No cambien su escencia, la neta el programa está bien vrgs.","authorDisplayName":"@Vladi_Santos","likeCount":0,"publishedAt":"2024-07-07T21:41:24Z","category_id":5,"category_description":"Felicitaciones y agradecimientos","Tokens_full":"['Que', 'pedo', 'con', 'la', 'gente', 'que', 'se', 'queja', 'de', 'que', 'digan', 'groserías', ',', 'cuando', 'es', 'parte', 'de', 'la', 'chispa', 'que', 'tiene', 'el', 'podcast', '.', 'No', 'cambien', 'su', 'escencia', ',', 'la', 'neta', 'el', 'programa', 'está', 'bien', 'vrgs', '.']","Tokens":"['Que', 'pedo', 'con', 'la', 'gente', 'que', 'se', 'queja', 'de', 'que', 'digan', 'groserías', 'cuando', 'es', 'parte', 'de', 'la', 'chispa', 'que', 'tiene', 'el', 'podcast', 'No', 'cambien', 'su', 'escencia', 'la', 'neta', 'el', 'programa', 'está', 'bien', 'vrgs']","Tokens_without_stopwords":"['Que', 'pedo', 'gente', 'queja', 'digan', 'groserías', 'parte', 'chispa', 'podcast', 'No', 'cambien', 'escencia', 'neta', 'programa', 'bien', 'vrgs']","Tokens_without_stopwords_stemmed":"['que', 'ped', 'gent', 'quej', 'dig', 'gros', 'part', 'chisp', 'podcast', 'no', 'cambi', 'escenci', 'net', 'program', 'bien', 'vrgs']","Tokens_lemmatized":"['que', 'pedar', 'con', 'el', 'gente', 'que', 'él', 'quejar', 'de', 'que', 'decir', 'grosería', ',', 'cuando', 'ser', 'parte', 'de', 'el', 'chispa', 'que', 'tener', 'el', 'podcast', '.', 'no', 'cambiar', 'su', 'escencia', ',', 'el', 'neta', 'el', 'programa', 'estar', 'bien', 'vrgs', '.']","Tokens_without_stopwords_lemmatized":"['que', 'pedar', 'gente', 'queja', 'decir', 'grosería', 'parte', 'chispa', 'podcast', 'no', 'cambiar', 'escencia', 'neta', 'programa', 'bien', 'vrgs']","_deepnote_index_column":6},{"id":"UgxZXPGB2G4B2mjIRc94AaABAg","videoId":"CPCN1Lqzc2U","textOriginal":"Mi parte favorita de historia para tontos es cuando Iker y Tecate hacen el amor","authorDisplayName":"@josueestrada6170","likeCount":2,"publishedAt":"2024-06-26T05:25:01Z","category_id":6,"category_description":"Comentarios humorísticos o memes","Tokens_full":"['Mi', 'parte', 'favorita', 'de', 'historia', 'para', 'tontos', 'es', 'cuando', 'Iker', 'y', 'Tecate', 'hacen', 'el', 'amor']","Tokens":"['Mi', 'parte', 'favorita', 'de', 'historia', 'para', 'tontos', 'es', 'cuando', 'Iker', 'y', 'Tecate', 'hacen', 'el', 'amor']","Tokens_without_stopwords":"['Mi', 'parte', 'favorita', 'historia', 'tontos', 'Iker', 'Tecate', 'hacen', 'amor']","Tokens_without_stopwords_stemmed":"['mi', 'part', 'favorit', 'histori', 'tont', 'iker', 'tecat', 'hac', 'amor']","Tokens_lemmatized":"['mi', 'parte', 'favorita', 'de', 'historia', 'para', 'tonto', 'ser', 'cuando', 'Iker', 'y', 'tecate', 'hacer', 'el', 'amor']","Tokens_without_stopwords_lemmatized":"['mi', 'parte', 'favorita', 'historia', 'tonto', 'Iker', 'tecate', 'hacer', 'amor']","_deepnote_index_column":7},{"id":"Ugyq_VGaO63x3zkeD454AaABAg","videoId":"yFHCam_Q9j4","textOriginal":"Weeeeeey","authorDisplayName":"@TheSuperdagon","likeCount":0,"publishedAt":"2024-04-25T00:01:49Z","category_id":6,"category_description":"Comentarios humorísticos o memes","Tokens_full":"['Weeeeeey']","Tokens":"['Weeeeeey']","Tokens_without_stopwords":"['Weeeeeey']","Tokens_without_stopwords_stemmed":"['weeeeeey']","Tokens_lemmatized":"['weeeeeey']","Tokens_without_stopwords_lemmatized":"['weeeeeey']","_deepnote_index_column":8},{"id":"UgyUr5nbHHrU7jLb2Ml4AaABAg","videoId":"cQ9RLDhq6JY","textOriginal":"Hay alguna forma de hacer una donacion al podcast sin ser parte del patreon?. Este es uno de mis podcast favoritos","authorDisplayName":"@carlosrosas9850","likeCount":0,"publishedAt":"2024-04-11T00:33:00Z","category_id":7,"category_description":"Comentarios generales","Tokens_full":"['Hay', 'alguna', 'forma', 'de', 'hacer', 'una', 'donacion', 'al', 'podcast', 'sin', 'ser', 'parte', 'del', 'patreon', '?', '.', 'Este', 'es', 'uno', 'de', 'mis', 'podcast', 'favoritos']","Tokens":"['Hay', 'alguna', 'forma', 'de', 'hacer', 'una', 'donacion', 'al', 'podcast', 'sin', 'ser', 'parte', 'del', 'patreon', 'Este', 'es', 'uno', 'de', 'mis', 'podcast', 'favoritos']","Tokens_without_stopwords":"['Hay', 'alguna', 'forma', 'hacer', 'donacion', 'podcast', 'ser', 'parte', 'patreon', 'Este', 'podcast', 'favoritos']","Tokens_without_stopwords_stemmed":"['hay', 'algun', 'form', 'hac', 'donacion', 'podcast', 'ser', 'part', 'patreon', 'este', 'podcast', 'favorit']","Tokens_lemmatized":"['haber', 'alguno', 'forma', 'de', 'hacer', 'uno', 'donación', 'a', 'el', 'podcast', 'sin', 'ser', 'parte', 'de', 'el', 'patreón', '?', '.', 'este', 'ser', 'uno', 'de', 'mi', 'podcast', 'favorito']","Tokens_without_stopwords_lemmatized":"['haber', 'alguno', 'forma', 'hacer', 'donación', 'podcast', 'ser', 'parte', 'patreón', 'este', 'podcast', 'favorito']","_deepnote_index_column":9}]},"text/plain":"                             id      videoId  \\\n0    UgwtT3n4ZD6aX2c3NrF4AaABAg  FXxcNjTZ4qo   \n1    Ugzlbev9x6glV6YNpyN4AaABAg  CPCN1Lqzc2U   \n2    UgzIKrDRdcGk13aMtul4AaABAg  ShW6FY-vbmo   \n3    Ugz5Q5R5ls4pXTXSi294AaABAg  HxMXLWqe9HQ   \n4    UgwKlLDQnWVL_LOpE1d4AaABAg  wCm4FNSnDPs   \n..                          ...          ...   \n917  Ugx0EIHPfWZ1EV9dG4p4AaABAg  yFHCam_Q9j4   \n918  UgwSryWi0MPvIPVHDop4AaABAg  7Jo3NR5lgd8   \n919  Ugyn1Vg1Epb_ZoYbspB4AaABAg  FOFeh_vfcD8   \n920  Ugzu_MhkRKhOWF0SIk14AaABAg  yFHCam_Q9j4   \n921  UgyBc01slQ0uyw9NxAh4AaABAg  ShW6FY-vbmo   \n\n                                          textOriginal  \\\n0            No es un mito, Paraguay 🇵🇾 si existe.....   \n1    Un podcast sobre la radio con DIANA URIBE, la ...   \n2    Cada vez que los escucho, muero de risa y me d...   \n3    Que buen capitulo, son geniales! El cristo del...   \n4    Gracias por el podcast de la semana, mis amore...   \n..                                                 ...   \n917  Me encantó todo. Gran episodio 🎉! ¡Felices 100...   \n918  Voy a investigar el conflicto de myanmar, ahor...   \n919  A ver a qué hora sacan otro podcast ? Ya pasar...   \n920  Me encantó ver las fotos en el video de YouTub...   \n921     El editor no puso la naumaquima en el cuadro 😢   \n\n               authorDisplayName  likeCount           publishedAt  \\\n0    @rosaelenarolonespinosa4666          1  2024-04-18T13:32:34Z   \n1                       @KarimVG          0  2024-06-26T05:30:57Z   \n2           @ceciliamendiola8646          2  2024-06-18T21:15:49Z   \n3    @anaberthalyochoaporras8262          0  2024-09-19T04:47:09Z   \n4                @LadySkywalkerW          0  2024-10-11T03:38:25Z   \n..                           ...        ...                   ...   \n917           @Cynthia_Gutierrez          0  2024-04-28T21:23:19Z   \n918          @antoniodejesus8241         15  2024-02-08T01:48:46Z   \n919           @YamilOrtega-rl9vb          1  2024-07-15T09:50:33Z   \n920              @veroaranda9618          0  2024-04-27T02:51:54Z   \n921              @Miguimin-fk8zc          0  2024-08-11T14:18:23Z   \n\n     category_id              category_description  \\\n0              7             Comentarios generales   \n1              5  Felicitaciones y agradecimientos   \n2              6  Comentarios humorísticos o memes   \n3              5  Felicitaciones y agradecimientos   \n4              5  Felicitaciones y agradecimientos   \n..           ...                               ...   \n917            5  Felicitaciones y agradecimientos   \n918            3           Experiencias personales   \n919            1    Quejas o sugerencias de mejora   \n920            5  Felicitaciones y agradecimientos   \n921            4  Correcciones o datos adicionales   \n\n                                           Tokens_full  \\\n0    ['No', 'es', 'un', 'mito', ',', 'Paraguay', 's...   \n1    ['Un', 'podcast', 'sobre', 'la', 'radio', 'con...   \n2    ['Cada', 'vez', 'que', 'los', 'escucho', ',', ...   \n3    ['Que', 'buen', 'capitulo', ',', 'son', 'genia...   \n4    ['Gracias', 'por', 'el', 'podcast', 'de', 'la'...   \n..                                                 ...   \n917  ['Me', 'encantó', 'todo', '.', 'Gran', 'episod...   \n918  ['Voy', 'a', 'investigar', 'el', 'conflicto', ...   \n919  ['A', 'ver', 'a', 'qué', 'hora', 'sacan', 'otr...   \n920  ['Me', 'encantó', 'ver', 'las', 'fotos', 'en',...   \n921  ['El', 'editor', 'no', 'puso', 'la', 'naumaqui...   \n\n                                                Tokens  \\\n0    ['No', 'es', 'un', 'mito', 'Paraguay', 'si', '...   \n1    ['Un', 'podcast', 'sobre', 'la', 'radio', 'con...   \n2    ['Cada', 'vez', 'que', 'los', 'escucho', 'muer...   \n3    ['Que', 'buen', 'capitulo', 'son', 'geniales',...   \n4    ['Gracias', 'por', 'el', 'podcast', 'de', 'la'...   \n..                                                 ...   \n917  ['Me', 'encantó', 'todo', 'Gran', 'episodio', ...   \n918  ['Voy', 'a', 'investigar', 'el', 'conflicto', ...   \n919  ['A', 'ver', 'a', 'qué', 'hora', 'sacan', 'otr...   \n920  ['Me', 'encantó', 'ver', 'las', 'fotos', 'en',...   \n921  ['El', 'editor', 'no', 'puso', 'la', 'naumaqui...   \n\n                              Tokens_without_stopwords  \\\n0    ['No', 'mito', 'Paraguay', 'si', 'existe', '...']   \n1    ['Un', 'podcast', 'radio', 'DIANA', 'URIBE', '...   \n2    ['Cada', 'vez', 'escucho', 'muero', 'risa', 'd...   \n3    ['Que', 'buen', 'capitulo', 'geniales', 'El', ...   \n4    ['Gracias', 'podcast', 'semana', 'amores', 'Lo...   \n..                                                 ...   \n917  ['Me', 'encantó', 'Gran', 'episodio', 'Felices...   \n918  ['Voy', 'investigar', 'conflicto', 'myanmar', ...   \n919  ['A', 'ver', 'hora', 'sacan', 'podcast', 'Ya',...   \n920  ['Me', 'encantó', 'ver', 'fotos', 'video', 'Yo...   \n921   ['El', 'editor', 'puso', 'naumaquima', 'cuadro']   \n\n                      Tokens_without_stopwords_stemmed  \\\n0      ['no', 'mit', 'paraguay', 'si', 'exist', '...']   \n1    ['un', 'podcast', 'radi', 'dian', 'urib', 'mej...   \n2    ['cad', 'vez', 'escuch', 'muer', 'ris', 'dan',...   \n3    ['que', 'buen', 'capitul', 'genial', 'el', 'cr...   \n4    ['graci', 'podcast', 'seman', 'amor', 'los', '...   \n..                                                 ...   \n917  ['me', 'encant', 'gran', 'episodi', 'felic', '...   \n918  ['voy', 'investig', 'conflict', 'myanm', 'ahor...   \n919  ['a', 'ver', 'hor', 'sac', 'podcast', 'ya', 'p...   \n920   ['me', 'encant', 'ver', 'fot', 'vide', 'youtub']   \n921      ['el', 'editor', 'pus', 'naumaquim', 'cuadr']   \n\n                                     Tokens_lemmatized  \\\n0    ['no', 'ser', 'uno', 'mito', ',', 'paraguay', ...   \n1    ['uno', 'podcast', 'sobre', 'el', 'radio', 'co...   \n2    ['cada', 'vez', 'que', 'él', 'escuchar', ',', ...   \n3    ['que', 'buen', 'capitulo', ',', 'ser', 'genia...   \n4    ['gracia', 'por', 'el', 'podcast', 'de', 'el',...   \n..                                                 ...   \n917  ['yo', 'encantar', 'todo', '.', 'Gran', 'episo...   \n918  ['ir', 'a', 'investigar', 'el', 'conflicto', '...   \n919  ['a', 'ver', 'a', 'qué', 'hora', 'sacar', 'otr...   \n920  ['yo', 'encantar', 'ver', 'el', 'foto', 'en', ...   \n921  ['el', 'editor', 'no', 'poner', 'el', 'naumaqu...   \n\n                   Tokens_without_stopwords_lemmatized  \n0    ['no', 'mito', 'paraguay', 'si', 'existir', '....  \n1    ['uno', 'podcast', 'radio', 'diana', 'URIBE', ...  \n2    ['cada', 'vez', 'escuchar', 'muero', 'risa', '...  \n3    ['que', 'buen', 'capitulo', 'genial', 'el', 'c...  \n4    ['gracia', 'podcast', 'semana', 'amor', 'el', ...  \n..                                                 ...  \n917  ['yo', 'encantar', 'gran', 'episodio', 'Felice...  \n918  ['ir', 'investigar', 'conflicto', 'myanmar', '...  \n919  ['a', 'ver', 'hora', 'sacar', 'podcast', 'ya',...  \n920  ['yo', 'encantar', 'ver', 'foto', 'vídeo', 'yo...  \n921  ['el', 'editor', 'poner', 'naumaquima', 'cuadro']  \n\n[922 rows x 14 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>videoId</th>\n      <th>textOriginal</th>\n      <th>authorDisplayName</th>\n      <th>likeCount</th>\n      <th>publishedAt</th>\n      <th>category_id</th>\n      <th>category_description</th>\n      <th>Tokens_full</th>\n      <th>Tokens</th>\n      <th>Tokens_without_stopwords</th>\n      <th>Tokens_without_stopwords_stemmed</th>\n      <th>Tokens_lemmatized</th>\n      <th>Tokens_without_stopwords_lemmatized</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>UgwtT3n4ZD6aX2c3NrF4AaABAg</td>\n      <td>FXxcNjTZ4qo</td>\n      <td>No es un mito, Paraguay 🇵🇾 si existe.....</td>\n      <td>@rosaelenarolonespinosa4666</td>\n      <td>1</td>\n      <td>2024-04-18T13:32:34Z</td>\n      <td>7</td>\n      <td>Comentarios generales</td>\n      <td>['No', 'es', 'un', 'mito', ',', 'Paraguay', 's...</td>\n      <td>['No', 'es', 'un', 'mito', 'Paraguay', 'si', '...</td>\n      <td>['No', 'mito', 'Paraguay', 'si', 'existe', '...']</td>\n      <td>['no', 'mit', 'paraguay', 'si', 'exist', '...']</td>\n      <td>['no', 'ser', 'uno', 'mito', ',', 'paraguay', ...</td>\n      <td>['no', 'mito', 'paraguay', 'si', 'existir', '....</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Ugzlbev9x6glV6YNpyN4AaABAg</td>\n      <td>CPCN1Lqzc2U</td>\n      <td>Un podcast sobre la radio con DIANA URIBE, la ...</td>\n      <td>@KarimVG</td>\n      <td>0</td>\n      <td>2024-06-26T05:30:57Z</td>\n      <td>5</td>\n      <td>Felicitaciones y agradecimientos</td>\n      <td>['Un', 'podcast', 'sobre', 'la', 'radio', 'con...</td>\n      <td>['Un', 'podcast', 'sobre', 'la', 'radio', 'con...</td>\n      <td>['Un', 'podcast', 'radio', 'DIANA', 'URIBE', '...</td>\n      <td>['un', 'podcast', 'radi', 'dian', 'urib', 'mej...</td>\n      <td>['uno', 'podcast', 'sobre', 'el', 'radio', 'co...</td>\n      <td>['uno', 'podcast', 'radio', 'diana', 'URIBE', ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>UgzIKrDRdcGk13aMtul4AaABAg</td>\n      <td>ShW6FY-vbmo</td>\n      <td>Cada vez que los escucho, muero de risa y me d...</td>\n      <td>@ceciliamendiola8646</td>\n      <td>2</td>\n      <td>2024-06-18T21:15:49Z</td>\n      <td>6</td>\n      <td>Comentarios humorísticos o memes</td>\n      <td>['Cada', 'vez', 'que', 'los', 'escucho', ',', ...</td>\n      <td>['Cada', 'vez', 'que', 'los', 'escucho', 'muer...</td>\n      <td>['Cada', 'vez', 'escucho', 'muero', 'risa', 'd...</td>\n      <td>['cad', 'vez', 'escuch', 'muer', 'ris', 'dan',...</td>\n      <td>['cada', 'vez', 'que', 'él', 'escuchar', ',', ...</td>\n      <td>['cada', 'vez', 'escuchar', 'muero', 'risa', '...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Ugz5Q5R5ls4pXTXSi294AaABAg</td>\n      <td>HxMXLWqe9HQ</td>\n      <td>Que buen capitulo, son geniales! El cristo del...</td>\n      <td>@anaberthalyochoaporras8262</td>\n      <td>0</td>\n      <td>2024-09-19T04:47:09Z</td>\n      <td>5</td>\n      <td>Felicitaciones y agradecimientos</td>\n      <td>['Que', 'buen', 'capitulo', ',', 'son', 'genia...</td>\n      <td>['Que', 'buen', 'capitulo', 'son', 'geniales',...</td>\n      <td>['Que', 'buen', 'capitulo', 'geniales', 'El', ...</td>\n      <td>['que', 'buen', 'capitul', 'genial', 'el', 'cr...</td>\n      <td>['que', 'buen', 'capitulo', ',', 'ser', 'genia...</td>\n      <td>['que', 'buen', 'capitulo', 'genial', 'el', 'c...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>UgwKlLDQnWVL_LOpE1d4AaABAg</td>\n      <td>wCm4FNSnDPs</td>\n      <td>Gracias por el podcast de la semana, mis amore...</td>\n      <td>@LadySkywalkerW</td>\n      <td>0</td>\n      <td>2024-10-11T03:38:25Z</td>\n      <td>5</td>\n      <td>Felicitaciones y agradecimientos</td>\n      <td>['Gracias', 'por', 'el', 'podcast', 'de', 'la'...</td>\n      <td>['Gracias', 'por', 'el', 'podcast', 'de', 'la'...</td>\n      <td>['Gracias', 'podcast', 'semana', 'amores', 'Lo...</td>\n      <td>['graci', 'podcast', 'seman', 'amor', 'los', '...</td>\n      <td>['gracia', 'por', 'el', 'podcast', 'de', 'el',...</td>\n      <td>['gracia', 'podcast', 'semana', 'amor', 'el', ...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>917</th>\n      <td>Ugx0EIHPfWZ1EV9dG4p4AaABAg</td>\n      <td>yFHCam_Q9j4</td>\n      <td>Me encantó todo. Gran episodio 🎉! ¡Felices 100...</td>\n      <td>@Cynthia_Gutierrez</td>\n      <td>0</td>\n      <td>2024-04-28T21:23:19Z</td>\n      <td>5</td>\n      <td>Felicitaciones y agradecimientos</td>\n      <td>['Me', 'encantó', 'todo', '.', 'Gran', 'episod...</td>\n      <td>['Me', 'encantó', 'todo', 'Gran', 'episodio', ...</td>\n      <td>['Me', 'encantó', 'Gran', 'episodio', 'Felices...</td>\n      <td>['me', 'encant', 'gran', 'episodi', 'felic', '...</td>\n      <td>['yo', 'encantar', 'todo', '.', 'Gran', 'episo...</td>\n      <td>['yo', 'encantar', 'gran', 'episodio', 'Felice...</td>\n    </tr>\n    <tr>\n      <th>918</th>\n      <td>UgwSryWi0MPvIPVHDop4AaABAg</td>\n      <td>7Jo3NR5lgd8</td>\n      <td>Voy a investigar el conflicto de myanmar, ahor...</td>\n      <td>@antoniodejesus8241</td>\n      <td>15</td>\n      <td>2024-02-08T01:48:46Z</td>\n      <td>3</td>\n      <td>Experiencias personales</td>\n      <td>['Voy', 'a', 'investigar', 'el', 'conflicto', ...</td>\n      <td>['Voy', 'a', 'investigar', 'el', 'conflicto', ...</td>\n      <td>['Voy', 'investigar', 'conflicto', 'myanmar', ...</td>\n      <td>['voy', 'investig', 'conflict', 'myanm', 'ahor...</td>\n      <td>['ir', 'a', 'investigar', 'el', 'conflicto', '...</td>\n      <td>['ir', 'investigar', 'conflicto', 'myanmar', '...</td>\n    </tr>\n    <tr>\n      <th>919</th>\n      <td>Ugyn1Vg1Epb_ZoYbspB4AaABAg</td>\n      <td>FOFeh_vfcD8</td>\n      <td>A ver a qué hora sacan otro podcast ? Ya pasar...</td>\n      <td>@YamilOrtega-rl9vb</td>\n      <td>1</td>\n      <td>2024-07-15T09:50:33Z</td>\n      <td>1</td>\n      <td>Quejas o sugerencias de mejora</td>\n      <td>['A', 'ver', 'a', 'qué', 'hora', 'sacan', 'otr...</td>\n      <td>['A', 'ver', 'a', 'qué', 'hora', 'sacan', 'otr...</td>\n      <td>['A', 'ver', 'hora', 'sacan', 'podcast', 'Ya',...</td>\n      <td>['a', 'ver', 'hor', 'sac', 'podcast', 'ya', 'p...</td>\n      <td>['a', 'ver', 'a', 'qué', 'hora', 'sacar', 'otr...</td>\n      <td>['a', 'ver', 'hora', 'sacar', 'podcast', 'ya',...</td>\n    </tr>\n    <tr>\n      <th>920</th>\n      <td>Ugzu_MhkRKhOWF0SIk14AaABAg</td>\n      <td>yFHCam_Q9j4</td>\n      <td>Me encantó ver las fotos en el video de YouTub...</td>\n      <td>@veroaranda9618</td>\n      <td>0</td>\n      <td>2024-04-27T02:51:54Z</td>\n      <td>5</td>\n      <td>Felicitaciones y agradecimientos</td>\n      <td>['Me', 'encantó', 'ver', 'las', 'fotos', 'en',...</td>\n      <td>['Me', 'encantó', 'ver', 'las', 'fotos', 'en',...</td>\n      <td>['Me', 'encantó', 'ver', 'fotos', 'video', 'Yo...</td>\n      <td>['me', 'encant', 'ver', 'fot', 'vide', 'youtub']</td>\n      <td>['yo', 'encantar', 'ver', 'el', 'foto', 'en', ...</td>\n      <td>['yo', 'encantar', 'ver', 'foto', 'vídeo', 'yo...</td>\n    </tr>\n    <tr>\n      <th>921</th>\n      <td>UgyBc01slQ0uyw9NxAh4AaABAg</td>\n      <td>ShW6FY-vbmo</td>\n      <td>El editor no puso la naumaquima en el cuadro 😢</td>\n      <td>@Miguimin-fk8zc</td>\n      <td>0</td>\n      <td>2024-08-11T14:18:23Z</td>\n      <td>4</td>\n      <td>Correcciones o datos adicionales</td>\n      <td>['El', 'editor', 'no', 'puso', 'la', 'naumaqui...</td>\n      <td>['El', 'editor', 'no', 'puso', 'la', 'naumaqui...</td>\n      <td>['El', 'editor', 'puso', 'naumaquima', 'cuadro']</td>\n      <td>['el', 'editor', 'pus', 'naumaquim', 'cuadr']</td>\n      <td>['el', 'editor', 'no', 'poner', 'el', 'naumaqu...</td>\n      <td>['el', 'editor', 'poner', 'naumaquima', 'cuadro']</td>\n    </tr>\n  </tbody>\n</table>\n<p>922 rows × 14 columns</p>\n</div>"},"metadata":{}}],"outputs_reference":"s3:deepnote-cell-outputs-production/8a7497d7-44b6-4897-b87e-d37a44013902","content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":"ff52d495","execution_start":1733898020119,"execution_millis":1,"execution_context_id":"41cfbd2e-b280-45a1-b4a8-14620261accf","cell_id":"108c4714aba24bb7a5a101af575e12e6","deepnote_cell_type":"code"},"source":"df_train.columns","block_group":"48c26f28ff5e4a399da2291bb9f47973","execution_count":23,"outputs":[{"output_type":"execute_result","execution_count":23,"data":{"text/plain":"Index(['id', 'videoId', 'textOriginal', 'authorDisplayName', 'likeCount',\n       'publishedAt', 'category_id', 'category_description', 'Tokens_full',\n       'Tokens', 'Tokens_without_stopwords',\n       'Tokens_without_stopwords_stemmed', 'Tokens_lemmatized',\n       'Tokens_without_stopwords_lemmatized'],\n      dtype='object')"},"metadata":{}}],"outputs_reference":"dbtable:cell_outputs/d12a66e5-114f-4475-99fc-69e2fff86434","content_dependencies":null},{"cell_type":"markdown","metadata":{"cell_id":"60c9aa386b454bbda08229893e3dbfb9","deepnote_cell_type":"markdown"},"source":"Create dataframe using only the `Tokens_without_stopwords_lemmatized` column from the `df_train`, `df_test` and `df_val` dataframe.","block_group":"0c490842d7a44fbf84eca14bf9056ebe"},{"cell_type":"code","metadata":{"source_hash":"9d32a950","execution_start":1733896909166,"execution_millis":0,"execution_context_id":"41cfbd2e-b280-45a1-b4a8-14620261accf","cell_id":"33aaba62f8d54e67a852f14f30341d64","deepnote_cell_type":"code"},"source":"import ast\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport pandas as pd\n\n# Función para evaluar de manera segura\ndef safe_eval(value):\n    \"\"\"\n    Convierte un valor de texto en su equivalente literal de Python, si es necesario.\n    Si ya es una lista, lo devuelve tal cual.\n    \"\"\"\n    try:\n        if isinstance(value, str):\n            return ast.literal_eval(value)\n        return value  # Si no es str, asume que ya es una lista\n    except (ValueError, SyntaxError):\n        print(f\"Error parsing: {value}\")\n        return []  # Devuelve una lista vacía en caso de error\n\n# Función para filtrar filas con listas no vacías\ndef filter_non_empty_rows(df, column):\n    \"\"\"\n    Filtra un DataFrame para que solo contenga filas donde la columna especificada\n    tiene listas no vacías.\n    \"\"\"\n    return df[df[column].apply(lambda x: len(x) > 0)]\n\n# Función para generar reportes detallados\ndef generate_classification_report(y_true, y_pred, dataset_name):\n    \"\"\"\n    Genera y muestra un reporte detallado de métricas de clasificación.\n    \"\"\"\n    print(f\"\\n=== Classification Report for {dataset_name} ===\")\n    print(classification_report(y_true, y_pred))\n    print(f\"Confusion Matrix for {dataset_name}:\\n{confusion_matrix(y_true, y_pred)}\")\n\n# Función principal para procesar una columna y generar reportes\ndef process_column_with_reports(df_train, df_test, df_val, column, classifier_class):\n    \"\"\"\n    Procesa una columna aplicando limpieza, filtrado y entrenamiento del modelo,\n    y genera reportes detallados de clasificación para train, test y val.\n    \"\"\"\n    # Limpieza\n    df_train[column] = df_train[column].apply(safe_eval)\n    df_test[column] = df_test[column].apply(safe_eval)\n    df_val[column] = df_val[column].apply(safe_eval)\n    \n    # Filtrar filas con listas no vacías\n    filtered_train_df = filter_non_empty_rows(df_train, column)\n    filtered_test_df = filter_non_empty_rows(df_test, column)\n    filtered_val_df = filter_non_empty_rows(df_val, column)\n    \n    # Dividir en X (features) e Y (target)\n    x_train = filtered_train_df[column]\n    y_train = filtered_train_df['category_id']\n    x_test = filtered_test_df[column]\n    y_test = filtered_test_df['category_id']\n    x_val = filtered_val_df[column]\n    y_val = filtered_val_df['category_id']\n    \n    # Crear y entrenar el clasificador\n    classifier = classifier_class()\n    classifier.fit(x_train, y_train)\n    \n    # Predecir para train, test y val\n    y_train_pred = classifier.predict(x_train)\n    y_test_pred = classifier.predict(x_test)\n    y_val_pred = classifier.predict(x_val)\n    \n    # Generar reportes detallados\n    generate_classification_report(y_train, y_train_pred, \"Train\")\n    generate_classification_report(y_test, y_test_pred, \"Test\")\n    generate_classification_report(y_val, y_val_pred, \"Validation\")\n    \n    return {\n        \"train_accuracy\": (y_train == y_train_pred).mean(),\n        \"test_accuracy\": (y_test == y_test_pred).mean(),\n        \"val_accuracy\": (y_val == y_val_pred).mean(),\n    }\n","block_group":"bf7c8f7e296a4b9eb1781ffb3310835f","execution_count":14,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":"98a1a283","execution_start":1733898054390,"execution_millis":889,"execution_context_id":"41cfbd2e-b280-45a1-b4a8-14620261accf","cell_id":"a7a30856eeef4eb1ad289db2d38f469a","deepnote_cell_type":"code"},"source":"cols = ['Tokens_full', 'Tokens', 'Tokens_without_stopwords', 'Tokens_without_stopwords_stemmed', 'Tokens_lemmatized',\n       'Tokens_without_stopwords_lemmatized']\n\nfor col in cols:\n    print(f\"Processing column: {col}\")\n    accuracies = process_column_with_reports(df_train, df_test, df_val, col, NaiveBayesClassifier)\n    print(f\"Accuracy Summary for {col}: {accuracies}\")\n","block_group":"26194603363043af9c4ba11363bc8eed","execution_count":24,"outputs":[{"name":"stdout","text":"Processing column: Tokens_full\n\n=== Classification Report for Train ===\n              precision    recall  f1-score   support\n\n           1       0.92      0.28      0.43        82\n           2       0.87      0.89      0.88       151\n           3       1.00      0.13      0.23        62\n           4       0.52      0.99      0.68       115\n           5       0.58      0.98      0.73       191\n           6       0.93      0.76      0.84       206\n           7       1.00      0.17      0.28       109\n\n    accuracy                           0.70       916\n   macro avg       0.83      0.60      0.58       916\nweighted avg       0.81      0.70      0.66       916\n\nConfusion Matrix for Train:\n[[ 23   6   0  27  26   0   0]\n [  0 134   0   6  11   0   0]\n [  1   1   8  14  38   0   0]\n [  0   1   0 114   0   0   0]\n [  0   2   0   1 188   0   0]\n [  0   5   0  17  27 157   0]\n [  1   5   0  41  32  12  18]]\n\n=== Classification Report for Test ===\n              precision    recall  f1-score   support\n\n           1       0.00      0.00      0.00         7\n           2       0.85      0.46      0.59        24\n           3       0.00      0.00      0.00         4\n           4       0.32      0.83      0.47        12\n           5       0.50      0.96      0.66        23\n           6       0.50      0.12      0.19        17\n           7       0.00      0.00      0.00         5\n\n    accuracy                           0.49        92\n   macro avg       0.31      0.34      0.27        92\nweighted avg       0.48      0.49      0.42        92\n\nConfusion Matrix for Test:\n[[ 0  1  0  3  3  0  0]\n [ 0 11  0  4  8  1  0]\n [ 0  0  0  0  4  0  0]\n [ 0  0  0 10  2  0  0]\n [ 0  0  0  1 22  0  0]\n [ 0  0  0 11  4  2  0]\n [ 0  1  0  2  1  1  0]]\n\n=== Classification Report for Validation ===\n              precision    recall  f1-score   support\n\n           2       1.00      0.67      0.80         3\n           3       0.00      0.00      0.00         1\n           4       0.33      0.50      0.40         2\n           5       0.00      0.00      0.00         1\n           6       0.00      0.00      0.00         2\n           7       0.00      0.00      0.00         2\n\n    accuracy                           0.27        11\n   macro avg       0.22      0.19      0.20        11\nweighted avg       0.33      0.27      0.29        11\n\nConfusion Matrix for Validation:\n[[2 0 1 0 0 0]\n [0 0 1 0 0 0]\n [0 0 1 0 1 0]\n [0 0 0 0 1 0]\n [0 0 0 2 0 0]\n [0 0 0 1 1 0]]\nAccuracy Summary for Tokens_full: {'train_accuracy': 0.7008733624454149, 'test_accuracy': 0.4891304347826087, 'val_accuracy': 0.2727272727272727}\nProcessing column: Tokens\n/root/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/root/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/root/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/root/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/root/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/root/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/root/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/root/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/root/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/root/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/root/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/root/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n\n=== Classification Report for Train ===\n              precision    recall  f1-score   support\n\n           1       0.94      0.39      0.55        82\n           2       0.89      0.89      0.89       151\n           3       1.00      0.18      0.30        62\n           4       0.58      0.99      0.73       115\n           5       0.58      0.98      0.73       191\n           6       0.94      0.81      0.87       206\n           7       1.00      0.21      0.35       109\n\n    accuracy                           0.73       916\n   macro avg       0.85      0.64      0.63       916\nweighted avg       0.82      0.73      0.70       916\n\nConfusion Matrix for Train:\n[[ 32   6   0  18  26   0   0]\n [  0 134   0   5  12   0   0]\n [  1   0  11  11  39   0   0]\n [  0   1   0 114   0   0   0]\n [  0   2   0   1 188   0   0]\n [  0   4   0  13  23 166   0]\n [  1   4   0  36  35  10  23]]\n\n=== Classification Report for Test ===\n              precision    recall  f1-score   support\n\n           1       0.00      0.00      0.00         7\n           2       0.79      0.46      0.58        24\n           3       0.00      0.00      0.00         4\n           4       0.31      0.75      0.44        12\n           5       0.50      0.96      0.66        23\n           6       0.40      0.12      0.18        17\n           7       0.00      0.00      0.00         5\n\n    accuracy                           0.48        92\n   macro avg       0.29      0.33      0.27        92\nweighted avg       0.44      0.48      0.41        92\n\nConfusion Matrix for Test:\n[[ 0  1  0  3  3  0  0]\n [ 0 11  0  3  9  1  0]\n [ 0  0  0  0  4  0  0]\n [ 0  1  0  9  2  0  0]\n [ 0  0  0  1 22  0  0]\n [ 0  0  0 11  4  2  0]\n [ 0  1  0  2  0  2  0]]\n\n=== Classification Report for Validation ===\n              precision    recall  f1-score   support\n\n           2       1.00      0.67      0.80         3\n           3       0.00      0.00      0.00         1\n           4       0.33      0.50      0.40         2\n           5       0.00      0.00      0.00         1\n           6       0.00      0.00      0.00         2\n           7       0.00      0.00      0.00         2\n\n    accuracy                           0.27        11\n   macro avg       0.22      0.19      0.20        11\nweighted avg       0.33      0.27      0.29        11\n\nConfusion Matrix for Validation:\n[[2 0 1 0 0 0]\n [0 0 1 0 0 0]\n [0 0 1 0 1 0]\n [0 0 0 0 1 0]\n [0 0 0 2 0 0]\n [0 0 0 1 1 0]]\nAccuracy Summary for Tokens: {'train_accuracy': 0.7292576419213974, 'test_accuracy': 0.4782608695652174, 'val_accuracy': 0.2727272727272727}\nProcessing column: Tokens_without_stopwords\n\n=== Classification Report for Train ===\n              precision    recall  f1-score   support\n\n           1       0.98      0.76      0.86        82\n           2       0.90      0.97      0.94       151\n           3       1.00      0.71      0.83        62\n           4       0.94      0.96      0.95       115\n           5       0.74      0.98      0.84       191\n           6       0.92      0.95      0.94       206\n           7       1.00      0.59      0.74       109\n\n    accuracy                           0.88       916\n   macro avg       0.93      0.84      0.87       916\nweighted avg       0.90      0.88      0.88       916\n\nConfusion Matrix for Train:\n[[ 62   5   0   0  14   1   0]\n [  0 147   0   0   4   0   0]\n [  1   0  44   1  16   0   0]\n [  0   2   0 110   2   1   0]\n [  0   2   0   0 188   1   0]\n [  0   1   0   0  10 195   0]\n [  0   6   0   6  20  13  64]]\n\n=== Classification Report for Test ===\n              precision    recall  f1-score   support\n\n           1       1.00      0.14      0.25         7\n           2       0.78      0.58      0.67        24\n           3       0.00      0.00      0.00         4\n           4       0.36      0.33      0.35        12\n           5       0.45      0.91      0.60        23\n           6       0.43      0.35      0.39        17\n           7       0.00      0.00      0.00         5\n\n    accuracy                           0.50        92\n   macro avg       0.43      0.33      0.32        92\nweighted avg       0.52      0.50      0.46        92\n\nConfusion Matrix for Test:\n[[ 1  1  0  1  4  0  0]\n [ 0 14  0  0  9  1  0]\n [ 0  0  0  0  4  0  0]\n [ 0  2  0  4  3  3  0]\n [ 0  0  0  0 21  2  0]\n [ 0  0  1  4  6  6  0]\n [ 0  1  0  2  0  2  0]]\n\n=== Classification Report for Validation ===\n              precision    recall  f1-score   support\n\n           2       1.00      0.67      0.80         3\n           3       0.00      0.00      0.00         1\n           4       0.00      0.00      0.00         2\n           5       0.00      0.00      0.00         1\n           6       0.20      0.50      0.29         2\n           7       1.00      0.50      0.67         2\n\n    accuracy                           0.36        11\n   macro avg       0.37      0.28      0.29        11\nweighted avg       0.49      0.36      0.39        11\n\nConfusion Matrix for Validation:\n[[2 0 0 0 1 0]\n [0 0 0 1 0 0]\n [0 0 0 1 1 0]\n [0 0 0 0 1 0]\n [0 0 0 1 1 0]\n [0 0 0 0 1 1]]\nAccuracy Summary for Tokens_without_stopwords: {'train_accuracy': 0.8842794759825328, 'test_accuracy': 0.5, 'val_accuracy': 0.36363636363636365}\nProcessing column: Tokens_without_stopwords_stemmed\n\n=== Classification Report for Train ===\n              precision    recall  f1-score   support\n\n           1       0.97      0.48      0.64        82\n           2       0.82      0.86      0.84       151\n           3       1.00      0.39      0.56        62\n           4       0.81      0.91      0.86       115\n           5       0.57      0.98      0.72       191\n           6       0.87      0.85      0.86       206\n           7       1.00      0.33      0.50       109\n\n    accuracy                           0.76       916\n   macro avg       0.86      0.69      0.71       916\nweighted avg       0.83      0.76      0.75       916\n\n/root/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/root/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/root/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/root/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/root/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/root/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/root/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/root/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/root/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/root/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/root/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/root/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\nConfusion Matrix for Train:\n[[ 39   8   0   3  30   2   0]\n [  0 130   0   2  16   3   0]\n [  1   0  24   4  31   2   0]\n [  0   4   0 105   5   1   0]\n [  0   3   0   0 187   1   0]\n [  0   5   0   4  21 176   0]\n [  0   9   0  11  36  17  36]]\n\n=== Classification Report for Test ===\n              precision    recall  f1-score   support\n\n           1       1.00      0.14      0.25         7\n           2       0.68      0.54      0.60        24\n           3       0.00      0.00      0.00         4\n           4       0.47      0.58      0.52        12\n           5       0.48      0.96      0.64        23\n           6       0.64      0.41      0.50        17\n           7       0.00      0.00      0.00         5\n\n    accuracy                           0.54        92\n   macro avg       0.47      0.38      0.36        92\nweighted avg       0.55      0.54      0.50        92\n\nConfusion Matrix for Test:\n[[ 1  1  0  0  5  0  0]\n [ 0 13  0  1  8  2  0]\n [ 0  0  0  0  4  0  0]\n [ 0  2  0  7  2  1  0]\n [ 0  0  0  1 22  0  0]\n [ 0  1  0  5  4  7  0]\n [ 0  2  0  1  1  1  0]]\n\n=== Classification Report for Validation ===\n              precision    recall  f1-score   support\n\n           2       0.67      0.67      0.67         3\n           3       0.00      0.00      0.00         1\n           4       0.50      0.50      0.50         2\n           5       0.00      0.00      0.00         1\n           6       0.50      0.50      0.50         2\n           7       1.00      0.50      0.67         2\n\n    accuracy                           0.45        11\n   macro avg       0.44      0.36      0.39        11\nweighted avg       0.55      0.45      0.48        11\n\nConfusion Matrix for Validation:\n[[2 0 1 0 0 0]\n [0 0 0 1 0 0]\n [0 0 1 1 0 0]\n [0 0 0 0 1 0]\n [0 0 0 1 1 0]\n [1 0 0 0 0 1]]\nAccuracy Summary for Tokens_without_stopwords_stemmed: {'train_accuracy': 0.7609170305676856, 'test_accuracy': 0.5434782608695652, 'val_accuracy': 0.45454545454545453}\nProcessing column: Tokens_lemmatized\n\n=== Classification Report for Train ===\n              precision    recall  f1-score   support\n\n           1       1.00      0.10      0.18        82\n           2       0.88      0.72      0.79       151\n           3       1.00      0.06      0.12        62\n           4       0.51      0.98      0.67       115\n           5       0.48      1.00      0.65       194\n           6       0.95      0.69      0.80       206\n           7       1.00      0.12      0.22       112\n\n    accuracy                           0.63       922\n   macro avg       0.83      0.53      0.49       922\nweighted avg       0.80      0.63      0.58       922\n\nConfusion Matrix for Train:\n[[  8   5   0  24  44   1   0]\n [  0 109   0  11  31   0   0]\n [  0   0   4  13  45   0   0]\n [  0   1   0 113   1   0   0]\n [  0   0   0   0 194   0   0]\n [  0   2   0  20  42 142   0]\n [  0   7   0  41  44   6  14]]\n\n=== Classification Report for Test ===\n              precision    recall  f1-score   support\n\n           1       0.00      0.00      0.00         7\n           2       0.82      0.38      0.51        24\n           3       0.00      0.00      0.00         4\n           4       0.36      0.75      0.49        12\n           5       0.40      0.91      0.56        23\n           6       0.50      0.12      0.19        17\n           7       0.00      0.00      0.00         5\n\n    accuracy                           0.45        92\n   macro avg       0.30      0.31      0.25        92\nweighted avg       0.45      0.45      0.37        92\n\nConfusion Matrix for Test:\n[[ 0  1  0  1  5  0  0]\n [ 0  9  0  3 11  1  0]\n [ 0  0  0  1  3  0  0]\n [ 0  0  0  9  3  0  0]\n [ 0  0  0  2 21  0  0]\n [ 0  0  0  9  6  2  0]\n [ 0  1  0  0  3  1  0]]\n\n=== Classification Report for Validation ===\n              precision    recall  f1-score   support\n\n           2       1.00      0.67      0.80         3\n           3       0.00      0.00      0.00         1\n           4       0.40      1.00      0.57         2\n           5       0.00      0.00      0.00         1\n           6       0.00      0.00      0.00         2\n           7       0.00      0.00      0.00         2\n\n    accuracy                           0.36        11\n   macro avg       0.23      0.28      0.23        11\nweighted avg       0.35      0.36      0.32        11\n\nConfusion Matrix for Validation:\n[[2 0 1 0 0 0]\n [0 0 1 0 0 0]\n [0 0 2 0 0 0]\n [0 0 0 0 1 0]\n [0 0 1 1 0 0]\n [0 0 0 2 0 0]]\nAccuracy Summary for Tokens_lemmatized: {'train_accuracy': 0.6334056399132321, 'test_accuracy': 0.44565217391304346, 'val_accuracy': 0.36363636363636365}\nProcessing column: Tokens_without_stopwords_lemmatized\n\n=== Classification Report for Train ===\n              precision    recall  f1-score   support\n\n           1       1.00      0.51      0.68        82\n           2       0.85      0.85      0.85       151\n           3       1.00      0.44      0.61        62\n           4       0.85      0.95      0.90       115\n           5       0.60      0.98      0.74       191\n           6       0.87      0.91      0.89       206\n           7       1.00      0.36      0.53       109\n\n    accuracy                           0.79       916\n   macro avg       0.88      0.71      0.74       916\nweighted avg       0.84      0.79      0.77       916\n\nConfusion Matrix for Train:\n[[ 42   6   0   2  29   3   0]\n [  0 128   0   3  19   1   0]\n [  0   0  27   4  28   3   0]\n [  0   2   0 109   3   1   0]\n [  0   2   0   0 188   1   0]\n [  0   4   0   1  14 187   0]\n [  0   8   0   9  34  19  39]]\n\n=== Classification Report for Test ===\n              precision    recall  f1-score   support\n\n           1       1.00      0.14      0.25         7\n           2       0.65      0.46      0.54        24\n           3       0.00      0.00      0.00         4\n           4       0.44      0.58      0.50        12\n           5       0.43      0.87      0.58        23\n           6       0.67      0.47      0.55        17\n           7       0.00      0.00      0.00         5\n\n    accuracy                           0.51        92\n   macro avg       0.46      0.36      0.35        92\nweighted avg       0.53      0.51      0.47        92\n\nConfusion Matrix for Test:\n[[ 1  1  0  0  5  0  0]\n [ 0 11  0  1 10  2  0]\n [ 0  0  0  0  4  0  0]\n [ 0  3  0  7  1  1  0]\n [ 0  1  0  2 20  0  0]\n [ 0  0  0  4  5  8  0]\n [ 0  1  0  2  1  1  0]]\n\n=== Classification Report for Validation ===\n              precision    recall  f1-score   support\n\n           2       1.00      0.67      0.80         3\n           3       0.00      0.00      0.00         1\n           4       0.00      0.00      0.00         2\n           5       0.00      0.00      0.00         1\n           6       0.33      0.50      0.40         2\n           7       1.00      0.50      0.67         2\n\n    accuracy                           0.36        11\n   macro avg       0.39      0.28      0.31        11\nweighted avg       0.52      0.36      0.41        11\n\nConfusion Matrix for Validation:\n[[2 0 1 0 0 0]\n [0 0 0 1 0 0]\n [0 0 0 1 1 0]\n [0 0 0 0 1 0]\n [0 0 0 1 1 0]\n [0 0 0 1 0 1]]\nAccuracy Summary for Tokens_without_stopwords_lemmatized: {'train_accuracy': 0.7860262008733624, 'test_accuracy': 0.5108695652173914, 'val_accuracy': 0.36363636363636365}\n/root/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/root/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/root/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/root/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/root/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/root/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/root/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/root/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/root/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/root/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/root/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/root/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"}],"outputs_reference":"s3:deepnote-cell-outputs-production/87666195-fd83-4b7f-b088-8d72c3d8debe","content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":"9ce8fb41","execution_start":1733897501841,"execution_millis":53,"execution_context_id":"41cfbd2e-b280-45a1-b4a8-14620261accf","cell_id":"416ee5e5a6004a43bbb9327cb9d2ebe9","deepnote_cell_type":"code"},"source":"cols = ['Tokens_without_stopwords']\n\nfor col in cols:\n    print(f\"Processing column: {col}\")\n    accuracies = process_column_with_reports(df_train_2, df_test_2, df_val_2, col, NaiveBayesClassifier)\n    print(f\"Accuracy Summary for {col}: {accuracies}\")\n","block_group":"f39121face5b42f390d587f38bb67c99","execution_count":21,"outputs":[{"name":"stdout","text":"Processing column: Tokens_without_stopwords\n\n=== Classification Report for Train ===\n              precision    recall  f1-score   support\n\n           1       0.87      0.41      0.55        81\n           2       0.63      0.71      0.67       145\n           3       0.90      0.31      0.46        61\n           4       0.64      0.67      0.65       111\n           5       0.50      0.95      0.65       195\n           6       0.77      0.55      0.64       179\n           7       1.00      0.19      0.32        80\n\n    accuracy                           0.62       852\n   macro avg       0.76      0.54      0.56       852\nweighted avg       0.71      0.62      0.60       852\n\nConfusion Matrix for Train:\n[[ 33  15   0   3  26   4   0]\n [  0 103   1   7  31   3   0]\n [  2   4  19   4  30   2   0]\n [  0   9   0  74  21   7   0]\n [  0   7   0   1 185   2   0]\n [  1  14   0  12  54  98   0]\n [  2  12   1  14  24  12  15]]\n\n=== Classification Report for Test ===\n              precision    recall  f1-score   support\n\n           1       0.00      0.00      0.00         5\n           2       0.47      0.45      0.46        20\n           3       0.50      0.20      0.29         5\n           4       0.27      0.25      0.26        12\n           5       0.28      0.92      0.43        13\n           6       0.50      0.16      0.24        19\n           7       1.00      0.12      0.22         8\n\n    accuracy                           0.35        82\n   macro avg       0.43      0.30      0.27        82\nweighted avg       0.44      0.35      0.31        82\n\nConfusion Matrix for Test:\n[[ 0  2  0  0  3  0  0]\n [ 0  9  1  3  7  0  0]\n [ 0  0  1  0  3  1  0]\n [ 0  3  0  3  5  1  0]\n [ 0  1  0  0 12  0  0]\n [ 0  3  0  3 10  3  0]\n [ 0  1  0  2  3  1  1]]\n\n=== Classification Report for Validation ===\n              precision    recall  f1-score   support\n\n           2       1.00      1.00      1.00         4\n           4       0.00      0.00      0.00         1\n           5       0.00      0.00      0.00         0\n           6       0.00      0.00      0.00         3\n           7       0.00      0.00      0.00         1\n\n    accuracy                           0.44         9\n   macro avg       0.20      0.20      0.20         9\nweighted avg       0.44      0.44      0.44         9\n\nConfusion Matrix for Validation:\n[[4 0 0 0 0]\n [0 0 1 0 0]\n [0 0 0 0 0]\n [0 0 3 0 0]\n [0 0 1 0 0]]\nAccuracy Summary for Tokens_without_stopwords: {'train_accuracy': 0.6185446009389671, 'test_accuracy': 0.35365853658536583, 'val_accuracy': 0.4444444444444444}\n/root/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/root/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/root/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/root/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/root/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/root/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/root/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/root/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/root/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"}],"outputs_reference":"s3:deepnote-cell-outputs-production/74c99f82-dfec-493a-8b05-ae2b5499de2b","content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":"3509d8cb","execution_start":1733898209140,"execution_millis":0,"execution_context_id":"41cfbd2e-b280-45a1-b4a8-14620261accf","cell_id":"2ad4eea0256b4721bb8c4f8f6b5b3492","deepnote_cell_type":"code"},"source":"def collect_accuracies(df_train, df_test, df_val, cols, classifier_class):\n    \"\"\"\n    Procesa cada columna, entrena y evalúa el modelo, y almacena las precisiones en un DataFrame.\n    \n    Parameters:\n        df_train, df_test, df_val: DataFrames de entrenamiento, prueba y validación.\n        cols: Lista de columnas a procesar.\n        classifier_class: Clase del modelo de clasificación a usar.\n        \n    Returns:\n        results_df: DataFrame con las precisiones para cada columna.\n    \"\"\"\n    results = []\n\n    for col in cols:\n        print(f\"Processing column: {col}\")\n        accuracies = process_column_with_reports(df_train, df_test, df_val, col, classifier_class)\n        results.append({\n            \"Column\": col,\n            \"Train Accuracy\": accuracies[\"train_accuracy\"],\n            \"Test Accuracy\": accuracies[\"test_accuracy\"],\n            \"Validation Accuracy\": accuracies[\"val_accuracy\"]\n        })\n    \n    results_df = pd.DataFrame(results)\n    return results_df","block_group":"9a9e3cab15544049b77e7ddc152f979d","execution_count":26,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":"889ab31a","execution_start":1733898230762,"execution_millis":638,"execution_context_id":"41cfbd2e-b280-45a1-b4a8-14620261accf","cell_id":"47dbb6a168794558ae6e9c37412be806","deepnote_cell_type":"code"},"source":"results_df = collect_accuracies(df_train, df_test, df_val, cols, NaiveBayesClassifier)\nresults_df","block_group":"ee1d38ffc0f249bc888f6ced75d13327","execution_count":27,"outputs":[{"name":"stdout","text":"Processing column: Tokens_full\n\n=== Classification Report for Train ===\n              precision    recall  f1-score   support\n\n           1       0.92      0.28      0.43        82\n           2       0.87      0.89      0.88       151\n           3       1.00      0.13      0.23        62\n           4       0.52      0.99      0.68       115\n           5       0.58      0.98      0.73       191\n           6       0.93      0.76      0.84       206\n           7       1.00      0.17      0.28       109\n\n    accuracy                           0.70       916\n   macro avg       0.83      0.60      0.58       916\nweighted avg       0.81      0.70      0.66       916\n\nConfusion Matrix for Train:\n[[ 23   6   0  27  26   0   0]\n [  0 134   0   6  11   0   0]\n [  1   1   8  14  38   0   0]\n [  0   1   0 114   0   0   0]\n [  0   2   0   1 188   0   0]\n [  0   5   0  17  27 157   0]\n [  1   5   0  41  32  12  18]]\n\n=== Classification Report for Test ===\n              precision    recall  f1-score   support\n\n           1       0.00      0.00      0.00         7\n           2       0.85      0.46      0.59        24\n           3       0.00      0.00      0.00         4\n           4       0.32      0.83      0.47        12\n           5       0.50      0.96      0.66        23\n           6       0.50      0.12      0.19        17\n           7       0.00      0.00      0.00         5\n\n    accuracy                           0.49        92\n   macro avg       0.31      0.34      0.27        92\nweighted avg       0.48      0.49      0.42        92\n\nConfusion Matrix for Test:\n[[ 0  1  0  3  3  0  0]\n [ 0 11  0  4  8  1  0]\n [ 0  0  0  0  4  0  0]\n [ 0  0  0 10  2  0  0]\n [ 0  0  0  1 22  0  0]\n [ 0  0  0 11  4  2  0]\n [ 0  1  0  2  1  1  0]]\n\n=== Classification Report for Validation ===\n              precision    recall  f1-score   support\n\n           2       1.00      0.67      0.80         3\n           3       0.00      0.00      0.00         1\n           4       0.33      0.50      0.40         2\n           5       0.00      0.00      0.00         1\n           6       0.00      0.00      0.00         2\n           7       0.00      0.00      0.00         2\n\n    accuracy                           0.27        11\n   macro avg       0.22      0.19      0.20        11\nweighted avg       0.33      0.27      0.29        11\n\nConfusion Matrix for Validation:\n[[2 0 1 0 0 0]\n [0 0 1 0 0 0]\n [0 0 1 0 1 0]\n [0 0 0 0 1 0]\n [0 0 0 2 0 0]\n [0 0 0 1 1 0]]\nProcessing column: Tokens\n/root/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/root/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/root/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/root/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/root/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/root/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/root/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/root/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/root/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/root/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/root/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/root/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n\n=== Classification Report for Train ===\n              precision    recall  f1-score   support\n\n           1       0.94      0.39      0.55        82\n           2       0.89      0.89      0.89       151\n           3       1.00      0.18      0.30        62\n           4       0.58      0.99      0.73       115\n           5       0.58      0.98      0.73       191\n           6       0.94      0.81      0.87       206\n           7       1.00      0.21      0.35       109\n\n    accuracy                           0.73       916\n   macro avg       0.85      0.64      0.63       916\nweighted avg       0.82      0.73      0.70       916\n\nConfusion Matrix for Train:\n[[ 32   6   0  18  26   0   0]\n [  0 134   0   5  12   0   0]\n [  1   0  11  11  39   0   0]\n [  0   1   0 114   0   0   0]\n [  0   2   0   1 188   0   0]\n [  0   4   0  13  23 166   0]\n [  1   4   0  36  35  10  23]]\n\n=== Classification Report for Test ===\n              precision    recall  f1-score   support\n\n           1       0.00      0.00      0.00         7\n           2       0.79      0.46      0.58        24\n           3       0.00      0.00      0.00         4\n           4       0.31      0.75      0.44        12\n           5       0.50      0.96      0.66        23\n           6       0.40      0.12      0.18        17\n           7       0.00      0.00      0.00         5\n\n    accuracy                           0.48        92\n   macro avg       0.29      0.33      0.27        92\nweighted avg       0.44      0.48      0.41        92\n\nConfusion Matrix for Test:\n[[ 0  1  0  3  3  0  0]\n [ 0 11  0  3  9  1  0]\n [ 0  0  0  0  4  0  0]\n [ 0  1  0  9  2  0  0]\n [ 0  0  0  1 22  0  0]\n [ 0  0  0 11  4  2  0]\n [ 0  1  0  2  0  2  0]]\n\n=== Classification Report for Validation ===\n              precision    recall  f1-score   support\n\n           2       1.00      0.67      0.80         3\n           3       0.00      0.00      0.00         1\n           4       0.33      0.50      0.40         2\n           5       0.00      0.00      0.00         1\n           6       0.00      0.00      0.00         2\n           7       0.00      0.00      0.00         2\n\n    accuracy                           0.27        11\n   macro avg       0.22      0.19      0.20        11\nweighted avg       0.33      0.27      0.29        11\n\nConfusion Matrix for Validation:\n[[2 0 1 0 0 0]\n [0 0 1 0 0 0]\n [0 0 1 0 1 0]\n [0 0 0 0 1 0]\n [0 0 0 2 0 0]\n [0 0 0 1 1 0]]\nProcessing column: Tokens_without_stopwords\n\n=== Classification Report for Train ===\n              precision    recall  f1-score   support\n\n           1       0.98      0.76      0.86        82\n           2       0.90      0.97      0.94       151\n           3       1.00      0.71      0.83        62\n           4       0.94      0.96      0.95       115\n           5       0.74      0.98      0.84       191\n           6       0.92      0.95      0.94       206\n           7       1.00      0.59      0.74       109\n\n    accuracy                           0.88       916\n   macro avg       0.93      0.84      0.87       916\nweighted avg       0.90      0.88      0.88       916\n\nConfusion Matrix for Train:\n[[ 62   5   0   0  14   1   0]\n [  0 147   0   0   4   0   0]\n [  1   0  44   1  16   0   0]\n [  0   2   0 110   2   1   0]\n [  0   2   0   0 188   1   0]\n [  0   1   0   0  10 195   0]\n [  0   6   0   6  20  13  64]]\n\n=== Classification Report for Test ===\n              precision    recall  f1-score   support\n\n           1       1.00      0.14      0.25         7\n           2       0.78      0.58      0.67        24\n           3       0.00      0.00      0.00         4\n           4       0.36      0.33      0.35        12\n           5       0.45      0.91      0.60        23\n           6       0.43      0.35      0.39        17\n           7       0.00      0.00      0.00         5\n\n    accuracy                           0.50        92\n   macro avg       0.43      0.33      0.32        92\nweighted avg       0.52      0.50      0.46        92\n\nConfusion Matrix for Test:\n[[ 1  1  0  1  4  0  0]\n [ 0 14  0  0  9  1  0]\n [ 0  0  0  0  4  0  0]\n [ 0  2  0  4  3  3  0]\n [ 0  0  0  0 21  2  0]\n [ 0  0  1  4  6  6  0]\n [ 0  1  0  2  0  2  0]]\n\n=== Classification Report for Validation ===\n              precision    recall  f1-score   support\n\n           2       1.00      0.67      0.80         3\n           3       0.00      0.00      0.00         1\n           4       0.00      0.00      0.00         2\n           5       0.00      0.00      0.00         1\n           6       0.20      0.50      0.29         2\n           7       1.00      0.50      0.67         2\n\n    accuracy                           0.36        11\n   macro avg       0.37      0.28      0.29        11\nweighted avg       0.49      0.36      0.39        11\n\nConfusion Matrix for Validation:\n[[2 0 0 0 1 0]\n [0 0 0 1 0 0]\n [0 0 0 1 1 0]\n [0 0 0 0 1 0]\n [0 0 0 1 1 0]\n [0 0 0 0 1 1]]\nProcessing column: Tokens_without_stopwords_stemmed\n\n=== Classification Report for Train ===\n              precision    recall  f1-score   support\n\n           1       0.97      0.48      0.64        82\n           2       0.82      0.86      0.84       151\n           3       1.00      0.39      0.56        62\n           4       0.81      0.91      0.86       115\n           5       0.57      0.98      0.72       191\n           6       0.87      0.85      0.86       206\n           7       1.00      0.33      0.50       109\n\n    accuracy                           0.76       916\n   macro avg       0.86      0.69      0.71       916\nweighted avg       0.83      0.76      0.75       916\n\nConfusion Matrix for Train:\n[[ 39   8   0   3  30   2   0]\n [  0 130   0   2  16   3   0]\n [  1   0  24   4  31   2   0]\n [  0   4   0 105   5   1   0]\n [  0   3   0   0 187   1   0]\n [  0   5   0   4  21 176   0]\n [  0   9   0  11  36  17  36]]\n\n=== Classification Report for Test ===\n              precision    recall  f1-score   support\n\n           1       1.00      0.14      0.25         7\n           2       0.68      0.54      0.60        24\n           3       0.00      0.00      0.00         4\n           4       0.47      0.58      0.52        12\n           5       0.48      0.96      0.64        23\n           6       0.64      0.41      0.50        17\n           7       0.00      0.00      0.00         5\n\n    accuracy                           0.54        92\n   macro avg       0.47      0.38      0.36        92\nweighted avg       0.55      0.54      0.50        92\n\n/root/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/root/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/root/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/root/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/root/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/root/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/root/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/root/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/root/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/root/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/root/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/root/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\nConfusion Matrix for Test:\n[[ 1  1  0  0  5  0  0]\n [ 0 13  0  1  8  2  0]\n [ 0  0  0  0  4  0  0]\n [ 0  2  0  7  2  1  0]\n [ 0  0  0  1 22  0  0]\n [ 0  1  0  5  4  7  0]\n [ 0  2  0  1  1  1  0]]\n\n=== Classification Report for Validation ===\n              precision    recall  f1-score   support\n\n           2       0.67      0.67      0.67         3\n           3       0.00      0.00      0.00         1\n           4       0.50      0.50      0.50         2\n           5       0.00      0.00      0.00         1\n           6       0.50      0.50      0.50         2\n           7       1.00      0.50      0.67         2\n\n    accuracy                           0.45        11\n   macro avg       0.44      0.36      0.39        11\nweighted avg       0.55      0.45      0.48        11\n\nConfusion Matrix for Validation:\n[[2 0 1 0 0 0]\n [0 0 0 1 0 0]\n [0 0 1 1 0 0]\n [0 0 0 0 1 0]\n [0 0 0 1 1 0]\n [1 0 0 0 0 1]]\nProcessing column: Tokens_lemmatized\n\n=== Classification Report for Train ===\n              precision    recall  f1-score   support\n\n           1       1.00      0.10      0.18        82\n           2       0.88      0.72      0.79       151\n           3       1.00      0.06      0.12        62\n           4       0.51      0.98      0.67       115\n           5       0.48      1.00      0.65       194\n           6       0.95      0.69      0.80       206\n           7       1.00      0.12      0.22       112\n\n    accuracy                           0.63       922\n   macro avg       0.83      0.53      0.49       922\nweighted avg       0.80      0.63      0.58       922\n\nConfusion Matrix for Train:\n[[  8   5   0  24  44   1   0]\n [  0 109   0  11  31   0   0]\n [  0   0   4  13  45   0   0]\n [  0   1   0 113   1   0   0]\n [  0   0   0   0 194   0   0]\n [  0   2   0  20  42 142   0]\n [  0   7   0  41  44   6  14]]\n\n=== Classification Report for Test ===\n              precision    recall  f1-score   support\n\n           1       0.00      0.00      0.00         7\n           2       0.82      0.38      0.51        24\n           3       0.00      0.00      0.00         4\n           4       0.36      0.75      0.49        12\n           5       0.40      0.91      0.56        23\n           6       0.50      0.12      0.19        17\n           7       0.00      0.00      0.00         5\n\n    accuracy                           0.45        92\n   macro avg       0.30      0.31      0.25        92\nweighted avg       0.45      0.45      0.37        92\n\nConfusion Matrix for Test:\n[[ 0  1  0  1  5  0  0]\n [ 0  9  0  3 11  1  0]\n [ 0  0  0  1  3  0  0]\n [ 0  0  0  9  3  0  0]\n [ 0  0  0  2 21  0  0]\n [ 0  0  0  9  6  2  0]\n [ 0  1  0  0  3  1  0]]\n\n=== Classification Report for Validation ===\n              precision    recall  f1-score   support\n\n           2       1.00      0.67      0.80         3\n           3       0.00      0.00      0.00         1\n           4       0.40      1.00      0.57         2\n           5       0.00      0.00      0.00         1\n           6       0.00      0.00      0.00         2\n           7       0.00      0.00      0.00         2\n\n    accuracy                           0.36        11\n   macro avg       0.23      0.28      0.23        11\nweighted avg       0.35      0.36      0.32        11\n\nConfusion Matrix for Validation:\n[[2 0 1 0 0 0]\n [0 0 1 0 0 0]\n [0 0 2 0 0 0]\n [0 0 0 0 1 0]\n [0 0 1 1 0 0]\n [0 0 0 2 0 0]]\nProcessing column: Tokens_without_stopwords_lemmatized\n\n=== Classification Report for Train ===\n              precision    recall  f1-score   support\n\n           1       1.00      0.51      0.68        82\n           2       0.85      0.85      0.85       151\n           3       1.00      0.44      0.61        62\n           4       0.85      0.95      0.90       115\n           5       0.60      0.98      0.74       191\n           6       0.87      0.91      0.89       206\n           7       1.00      0.36      0.53       109\n\n    accuracy                           0.79       916\n   macro avg       0.88      0.71      0.74       916\nweighted avg       0.84      0.79      0.77       916\n\nConfusion Matrix for Train:\n[[ 42   6   0   2  29   3   0]\n [  0 128   0   3  19   1   0]\n [  0   0  27   4  28   3   0]\n [  0   2   0 109   3   1   0]\n [  0   2   0   0 188   1   0]\n [  0   4   0   1  14 187   0]\n [  0   8   0   9  34  19  39]]\n\n=== Classification Report for Test ===\n              precision    recall  f1-score   support\n\n           1       1.00      0.14      0.25         7\n           2       0.65      0.46      0.54        24\n           3       0.00      0.00      0.00         4\n           4       0.44      0.58      0.50        12\n           5       0.43      0.87      0.58        23\n           6       0.67      0.47      0.55        17\n           7       0.00      0.00      0.00         5\n\n    accuracy                           0.51        92\n   macro avg       0.46      0.36      0.35        92\nweighted avg       0.53      0.51      0.47        92\n\nConfusion Matrix for Test:\n[[ 1  1  0  0  5  0  0]\n [ 0 11  0  1 10  2  0]\n [ 0  0  0  0  4  0  0]\n [ 0  3  0  7  1  1  0]\n [ 0  1  0  2 20  0  0]\n [ 0  0  0  4  5  8  0]\n [ 0  1  0  2  1  1  0]]\n\n=== Classification Report for Validation ===\n              precision    recall  f1-score   support\n\n           2       1.00      0.67      0.80         3\n           3       0.00      0.00      0.00         1\n           4       0.00      0.00      0.00         2\n           5       0.00      0.00      0.00         1\n           6       0.33      0.50      0.40         2\n           7       1.00      0.50      0.67         2\n\n    accuracy                           0.36        11\n   macro avg       0.39      0.28      0.31        11\nweighted avg       0.52      0.36      0.41        11\n\nConfusion Matrix for Validation:\n[[2 0 1 0 0 0]\n [0 0 0 1 0 0]\n [0 0 0 1 1 0]\n [0 0 0 0 1 0]\n [0 0 0 1 1 0]\n [0 0 0 1 0 1]]\n/root/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/root/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/root/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/root/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/root/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/root/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/root/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/root/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/root/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/root/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/root/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/root/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"},{"output_type":"execute_result","execution_count":27,"data":{"application/vnd.deepnote.dataframe.v3+json":{"column_count":4,"row_count":6,"columns":[{"name":"Column","dtype":"object","stats":{"unique_count":6,"nan_count":0,"categories":[{"name":"Tokens_full","count":1},{"name":"Tokens","count":1},{"name":"4 others","count":4}]}},{"name":"Train Accuracy","dtype":"float64","stats":{"unique_count":6,"nan_count":0,"min":"0.6334056399132321","max":"0.8842794759825328","histogram":[{"bin_start":0.6334056399132321,"bin_end":0.6584930235201621,"count":1},{"bin_start":0.6584930235201621,"bin_end":0.6835804071270922,"count":0},{"bin_start":0.6835804071270922,"bin_end":0.7086677907340223,"count":1},{"bin_start":0.7086677907340223,"bin_end":0.7337551743409524,"count":1},{"bin_start":0.7337551743409524,"bin_end":0.7588425579478824,"count":0},{"bin_start":0.7588425579478824,"bin_end":0.7839299415548124,"count":1},{"bin_start":0.7839299415548124,"bin_end":0.8090173251617425,"count":1},{"bin_start":0.8090173251617425,"bin_end":0.8341047087686726,"count":0},{"bin_start":0.8341047087686726,"bin_end":0.8591920923756027,"count":0},{"bin_start":0.8591920923756027,"bin_end":0.8842794759825328,"count":1}]}},{"name":"Test Accuracy","dtype":"float64","stats":{"unique_count":6,"nan_count":0,"min":"0.44565217391304346","max":"0.5434782608695652","histogram":[{"bin_start":0.44565217391304346,"bin_end":0.45543478260869563,"count":1},{"bin_start":0.45543478260869563,"bin_end":0.4652173913043478,"count":0},{"bin_start":0.4652173913043478,"bin_end":0.475,"count":0},{"bin_start":0.475,"bin_end":0.48478260869565215,"count":1},{"bin_start":0.48478260869565215,"bin_end":0.4945652173913043,"count":1},{"bin_start":0.4945652173913043,"bin_end":0.5043478260869565,"count":1},{"bin_start":0.5043478260869565,"bin_end":0.5141304347826087,"count":1},{"bin_start":0.5141304347826087,"bin_end":0.5239130434782608,"count":0},{"bin_start":0.5239130434782608,"bin_end":0.533695652173913,"count":0},{"bin_start":0.533695652173913,"bin_end":0.5434782608695652,"count":1}]}},{"name":"Validation Accuracy","dtype":"float64","stats":{"unique_count":3,"nan_count":0,"min":"0.2727272727272727","max":"0.45454545454545453","histogram":[{"bin_start":0.2727272727272727,"bin_end":0.2909090909090909,"count":2},{"bin_start":0.2909090909090909,"bin_end":0.3090909090909091,"count":0},{"bin_start":0.3090909090909091,"bin_end":0.32727272727272727,"count":0},{"bin_start":0.32727272727272727,"bin_end":0.34545454545454546,"count":0},{"bin_start":0.34545454545454546,"bin_end":0.36363636363636365,"count":0},{"bin_start":0.36363636363636365,"bin_end":0.3818181818181818,"count":3},{"bin_start":0.3818181818181818,"bin_end":0.39999999999999997,"count":0},{"bin_start":0.39999999999999997,"bin_end":0.41818181818181815,"count":0},{"bin_start":0.41818181818181815,"bin_end":0.43636363636363634,"count":0},{"bin_start":0.43636363636363634,"bin_end":0.45454545454545453,"count":1}]}},{"name":"_deepnote_index_column","dtype":"int64"}],"rows":[{"Column":"Tokens_full","Train Accuracy":0.7008733624454149,"Test Accuracy":0.4891304347826087,"Validation Accuracy":0.2727272727272727,"_deepnote_index_column":0},{"Column":"Tokens","Train Accuracy":0.7292576419213974,"Test Accuracy":0.4782608695652174,"Validation Accuracy":0.2727272727272727,"_deepnote_index_column":1},{"Column":"Tokens_without_stopwords","Train Accuracy":0.8842794759825328,"Test Accuracy":0.5,"Validation Accuracy":0.36363636363636365,"_deepnote_index_column":2},{"Column":"Tokens_without_stopwords_stemmed","Train Accuracy":0.7609170305676856,"Test Accuracy":0.5434782608695652,"Validation Accuracy":0.45454545454545453,"_deepnote_index_column":3},{"Column":"Tokens_lemmatized","Train Accuracy":0.6334056399132321,"Test Accuracy":0.44565217391304346,"Validation Accuracy":0.36363636363636365,"_deepnote_index_column":4},{"Column":"Tokens_without_stopwords_lemmatized","Train Accuracy":0.7860262008733624,"Test Accuracy":0.5108695652173914,"Validation Accuracy":0.36363636363636365,"_deepnote_index_column":5}]},"text/plain":"                                Column  Train Accuracy  Test Accuracy  \\\n0                          Tokens_full        0.700873       0.489130   \n1                               Tokens        0.729258       0.478261   \n2             Tokens_without_stopwords        0.884279       0.500000   \n3     Tokens_without_stopwords_stemmed        0.760917       0.543478   \n4                    Tokens_lemmatized        0.633406       0.445652   \n5  Tokens_without_stopwords_lemmatized        0.786026       0.510870   \n\n   Validation Accuracy  \n0             0.272727  \n1             0.272727  \n2             0.363636  \n3             0.454545  \n4             0.363636  \n5             0.363636  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Column</th>\n      <th>Train Accuracy</th>\n      <th>Test Accuracy</th>\n      <th>Validation Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Tokens_full</td>\n      <td>0.700873</td>\n      <td>0.489130</td>\n      <td>0.272727</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Tokens</td>\n      <td>0.729258</td>\n      <td>0.478261</td>\n      <td>0.272727</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Tokens_without_stopwords</td>\n      <td>0.884279</td>\n      <td>0.500000</td>\n      <td>0.363636</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Tokens_without_stopwords_stemmed</td>\n      <td>0.760917</td>\n      <td>0.543478</td>\n      <td>0.454545</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Tokens_lemmatized</td>\n      <td>0.633406</td>\n      <td>0.445652</td>\n      <td>0.363636</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Tokens_without_stopwords_lemmatized</td>\n      <td>0.786026</td>\n      <td>0.510870</td>\n      <td>0.363636</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"outputs_reference":"s3:deepnote-cell-outputs-production/f1bca23f-a852-41bd-a12f-09edc8f258b6","content_dependencies":null},{"cell_type":"markdown","source":"<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=2820e488-6f1b-466d-af14-a66826f012e3' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>","metadata":{"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"}}],"nbformat":4,"nbformat_minor":0,"metadata":{"deepnote_notebook_id":"c2a6ec1c61a24da2bdde2075668c18a2"}}